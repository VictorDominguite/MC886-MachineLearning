{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erlRBrJIUyrB"
      },
      "source": [
        "# **Task \\#2**: Machine Learning MC886/MO444\n",
        "##**Classical Machine Learning Techniques**##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjNwzgz-UTLB",
        "outputId": "51843fcb-803b-4cda-dee0-25cc9cbfa385"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tobias Conran Zorzetto 166214\n",
            "Victor Costa Dominguite 245003\n"
          ]
        }
      ],
      "source": [
        "print('Tobias Conran Zorzetto' + ' 166214')\n",
        "print('Victor Costa Dominguite' + ' 245003')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1gEHx0gU-w2"
      },
      "source": [
        "## Objective:\n",
        "\n",
        "To explore **Linear Regression** and **Logistic Regression** alternatives and come up with the best possible model for the problems, at the same time avoiding overfitting (and also underfitting). In this work, we will train a model that use medical records from patients to predict patient survival."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkUuHD5MKhrk"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The purpose of this dataset is to predict the patients' survival from medical records. These data is available in [Google Sheets](https://docs.google.com/spreadsheets/d/18-PlYBnwD7yJoyGJOsaB5Wydc2iTG9sSnbuuV4t4efE/edit?usp=sharing), consisting in 299 patients with heart failure collected in 2015. \n",
        "\n",
        "**Data Dictionary**:\n",
        "\n",
        "- **AGE**: Age of the patient (years);\n",
        "\n",
        "- **ANAEMIA**: Decrease of red blood cells or hemoglobin (boolean);\n",
        "\n",
        "- **HIGH BLODD PRESSURE**: If the patient has hypertension (boolean);\n",
        "\n",
        "- **CREATININE PHOSPHOKINASE (CPK)**: Level of the CPK enzyme in the blood (mcg/L);\n",
        "\n",
        "- **DIABETES**: If the patient has diabetes (boolean);\n",
        "\n",
        "- **EJECTION FRACTION**: Percentage of blood leaving the heart at each contraction (percentage);\n",
        "\n",
        "- **PLATELETS**: Platelets in the blood (kiloplatelets/mL);\n",
        "\n",
        "- **SEX**: Woman or man (binary);\n",
        "\n",
        "- **SERUM CREATININE**: Level of serum creatinine in the blood (mg/dL);\n",
        "\n",
        "- **SERUM SODIUM**: Level of serum sodium in the blood (mEq/L);\n",
        "\n",
        "- **SMOKING**: If the patient smokes or not (boolean);\n",
        "\n",
        "- **TIME**: Follow-up period (days);\n",
        "\n",
        "- **DEATH EVENT**: If the patient deceased during the follow-up period (boolean);\n",
        "\n",
        "More information about the dataset: *Chicco, D., Jurman, G. Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone. BMC Med Inform Decis Mak 20, 16 (2020). https://doi.org/10.1186/s12911-020-1023-5*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "anh4gw-zV2ed",
        "outputId": "9b1a0025-53b3-456e-8432-ab811debc8e7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>DEATH_EVENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.0</td>\n",
              "      <td>No</td>\n",
              "      <td>582.0</td>\n",
              "      <td>No</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>265000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>130.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55.0</td>\n",
              "      <td>No</td>\n",
              "      <td>7861.0</td>\n",
              "      <td>No</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>263358.03</td>\n",
              "      <td>1.1</td>\n",
              "      <td>136.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.0</td>\n",
              "      <td>No</td>\n",
              "      <td>146.0</td>\n",
              "      <td>No</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162000.00</td>\n",
              "      <td>1.3</td>\n",
              "      <td>129.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>111.0</td>\n",
              "      <td>No</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>210000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>137.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>160.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>327000.00</td>\n",
              "      <td>2.7</td>\n",
              "      <td>116.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age anaemia  creatinine_phosphokinase diabetes  ejection_fraction   \n",
              "0  75.0      No                     582.0       No               20.0  \\\n",
              "1  55.0      No                    7861.0       No               38.0   \n",
              "2  65.0      No                     146.0       No               20.0   \n",
              "3  50.0     Yes                     111.0       No               20.0   \n",
              "4   NaN     Yes                     160.0      Yes               20.0   \n",
              "\n",
              "   high_blood_pressure  platelets  serum_creatinine  serum_sodium     sex   \n",
              "0                  1.0  265000.00               1.9         130.0  Female  \\\n",
              "1                  0.0  263358.03               1.1         136.0  Female   \n",
              "2                  0.0  162000.00               1.3         129.0  Female   \n",
              "3                  0.0  210000.00               1.9         137.0  Female   \n",
              "4                  0.0  327000.00               2.7         116.0    Male   \n",
              "\n",
              "  smoking  DEATH_EVENT  \n",
              "0      No            1  \n",
              "1      No            1  \n",
              "2     Yes            1  \n",
              "3      No            1  \n",
              "4      No            1  "
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv('heart_dataset.csv').drop(columns=['time'])\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQmaNgdX7L8O"
      },
      "source": [
        "### Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL0r1lFVO6Yd"
      },
      "source": [
        "(0.5 points) This part of the assignmente aims to analyze the dataset and preprocess the data for the models. To do so, a fews things to be considered: \n",
        "\n",
        "\n",
        "*   Are there any outliers?\n",
        "*   Are there missing values?\n",
        "*   How will you handle categorical variables?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Eq8csCfFEDyS",
        "outputId": "6612411e-41eb-4a12-a92c-af6082df2305"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>DEATH_EVENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>582.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>265000.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>130.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162000.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>129.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>210000.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>137.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>90.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>204000.0</td>\n",
              "      <td>2.1</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>75.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>246.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>127000.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>137.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>45.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>582.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>543000.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>90.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>390000.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>144.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>45.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>615.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>222000.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>141.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>63.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>179000.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>136.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>45.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2413.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>140000.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>140.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>259 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction   \n",
              "0    75.0      0.0                     582.0       0.0               20.0  \\\n",
              "2    65.0      0.0                     146.0       0.0               20.0   \n",
              "3    50.0      1.0                     111.0       0.0               20.0   \n",
              "5    90.0      1.0                      47.0       0.0               40.0   \n",
              "6    75.0      1.0                     246.0       0.0               15.0   \n",
              "..    ...      ...                       ...       ...                ...   \n",
              "287  45.0      0.0                     582.0       1.0               55.0   \n",
              "289  90.0      1.0                     337.0       0.0               38.0   \n",
              "290  45.0      0.0                     615.0       1.0               55.0   \n",
              "293  63.0      1.0                     103.0       1.0               35.0   \n",
              "297  45.0      0.0                    2413.0       0.0               38.0   \n",
              "\n",
              "     high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex   \n",
              "0                    1.0   265000.0               1.9         130.0  0.0  \\\n",
              "2                    0.0   162000.0               1.3         129.0  0.0   \n",
              "3                    0.0   210000.0               1.9         137.0  0.0   \n",
              "5                    1.0   204000.0               2.1         132.0  0.0   \n",
              "6                    0.0   127000.0               1.2         137.0  0.0   \n",
              "..                   ...        ...               ...           ...  ...   \n",
              "287                  0.0   543000.0               1.0         132.0  1.0   \n",
              "289                  0.0   390000.0               0.9         144.0  1.0   \n",
              "290                  0.0   222000.0               0.8         141.0  1.0   \n",
              "293                  0.0   179000.0               0.9         136.0  0.0   \n",
              "297                  0.0   140000.0               1.4         140.0  0.0   \n",
              "\n",
              "     smoking  DEATH_EVENT  \n",
              "0        0.0          1.0  \n",
              "2        1.0          1.0  \n",
              "3        0.0          1.0  \n",
              "5        1.0          1.0  \n",
              "6        0.0          1.0  \n",
              "..       ...          ...  \n",
              "287      0.0          0.0  \n",
              "289      0.0          0.0  \n",
              "290      0.0          0.0  \n",
              "293      1.0          0.0  \n",
              "297      1.0          0.0  \n",
              "\n",
              "[259 rows x 12 columns]"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Rows with missing values are removed from the dataset\n",
        "df = df.dropna(axis=0)\n",
        "\n",
        "# Dealing with categorical variables by replacing them with numerical values\n",
        "df['anaemia'].replace(['No', 'Yes'], [0, 1], inplace=True)\n",
        "df['diabetes'].replace(['No', 'Yes'], [0, 1], inplace=True)\n",
        "df['smoking'].replace(['No', 'Yes'], [0, 1], inplace=True)\n",
        "df['sex'].replace(['Female', 'Male'], [0, 1], inplace=True)\n",
        "df = df.astype('float64')\n",
        "\n",
        "# Calculates the Z-score and only keeps rows within 3 standard deviations of its\n",
        "# mean to avoid outliers\n",
        "df = df[(np.abs(stats.zscore(df)) < 3)]\n",
        "df = df.dropna(axis=0)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z-o2l0xEom-"
      },
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtWOiVbUW4T5"
      },
      "source": [
        "(0.75 points) This part of the assigment aims to predict the level of serum creatinine in the blod based on their medical records. \n",
        "\n",
        "*   Do we need to split the data into train, valid and test? How?\n",
        "*   Do we need to normalize the data? How? The normalization is equal to train, valid and test split?\n",
        "* **Target value: serum_creatinine**.\n",
        "\n",
        "Obs: drop the DEATH_EVENT column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "3JQo-C4DXq22"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>-0.275623</td>\n",
              "      <td>1.108037</td>\n",
              "      <td>-0.601574</td>\n",
              "      <td>-0.773592</td>\n",
              "      <td>-1.097586</td>\n",
              "      <td>-0.801179</td>\n",
              "      <td>-0.420499</td>\n",
              "      <td>0.103996</td>\n",
              "      <td>-0.719812</td>\n",
              "      <td>1.300804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>-0.526036</td>\n",
              "      <td>-0.897510</td>\n",
              "      <td>0.739516</td>\n",
              "      <td>-0.773592</td>\n",
              "      <td>0.179716</td>\n",
              "      <td>-0.801179</td>\n",
              "      <td>0.292708</td>\n",
              "      <td>0.922398</td>\n",
              "      <td>-0.719812</td>\n",
              "      <td>1.300804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>-1.110333</td>\n",
              "      <td>1.108037</td>\n",
              "      <td>-0.628784</td>\n",
              "      <td>1.285529</td>\n",
              "      <td>-0.671818</td>\n",
              "      <td>1.241264</td>\n",
              "      <td>-0.123330</td>\n",
              "      <td>-1.805610</td>\n",
              "      <td>1.381575</td>\n",
              "      <td>-0.764508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>0.141731</td>\n",
              "      <td>-0.897510</td>\n",
              "      <td>0.935821</td>\n",
              "      <td>-0.773592</td>\n",
              "      <td>0.009409</td>\n",
              "      <td>-0.801179</td>\n",
              "      <td>0.589878</td>\n",
              "      <td>-0.987207</td>\n",
              "      <td>-0.719812</td>\n",
              "      <td>1.300804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>-1.611159</td>\n",
              "      <td>-0.897510</td>\n",
              "      <td>-0.759006</td>\n",
              "      <td>-0.773592</td>\n",
              "      <td>-0.671818</td>\n",
              "      <td>-0.801179</td>\n",
              "      <td>-0.468047</td>\n",
              "      <td>-2.351211</td>\n",
              "      <td>-0.719812</td>\n",
              "      <td>1.300804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1.560738</td>\n",
              "      <td>-0.897510</td>\n",
              "      <td>-0.595743</td>\n",
              "      <td>1.285529</td>\n",
              "      <td>0.009409</td>\n",
              "      <td>-0.801179</td>\n",
              "      <td>-1.252575</td>\n",
              "      <td>2.013601</td>\n",
              "      <td>-0.719812</td>\n",
              "      <td>1.300804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>-1.778101</td>\n",
              "      <td>1.108037</td>\n",
              "      <td>-0.687093</td>\n",
              "      <td>-0.773592</td>\n",
              "      <td>0.179716</td>\n",
              "      <td>-0.801179</td>\n",
              "      <td>-0.337292</td>\n",
              "      <td>1.195199</td>\n",
              "      <td>1.381575</td>\n",
              "      <td>-0.764508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>0.475615</td>\n",
              "      <td>-0.897510</td>\n",
              "      <td>0.247783</td>\n",
              "      <td>-0.773592</td>\n",
              "      <td>1.031251</td>\n",
              "      <td>-0.801179</td>\n",
              "      <td>0.106775</td>\n",
              "      <td>0.103996</td>\n",
              "      <td>-0.719812</td>\n",
              "      <td>1.300804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>2.061563</td>\n",
              "      <td>-0.897510</td>\n",
              "      <td>0.247783</td>\n",
              "      <td>-0.773592</td>\n",
              "      <td>0.009409</td>\n",
              "      <td>-0.801179</td>\n",
              "      <td>0.106775</td>\n",
              "      <td>-0.714406</td>\n",
              "      <td>1.381575</td>\n",
              "      <td>-0.764508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>-0.275623</td>\n",
              "      <td>1.108037</td>\n",
              "      <td>-0.105954</td>\n",
              "      <td>-0.773592</td>\n",
              "      <td>0.179716</td>\n",
              "      <td>-0.801179</td>\n",
              "      <td>-1.074273</td>\n",
              "      <td>0.649597</td>\n",
              "      <td>1.381575</td>\n",
              "      <td>-0.764508</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>181 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          age   anaemia  creatinine_phosphokinase  diabetes   \n",
              "184 -0.275623  1.108037                 -0.601574 -0.773592  \\\n",
              "179 -0.526036 -0.897510                  0.739516 -0.773592   \n",
              "213 -1.110333  1.108037                 -0.628784  1.285529   \n",
              "108  0.141731 -0.897510                  0.935821 -0.773592   \n",
              "282 -1.611159 -0.897510                 -0.759006 -0.773592   \n",
              "..        ...       ...                       ...       ...   \n",
              "25   1.560738 -0.897510                 -0.595743  1.285529   \n",
              "206 -1.778101  1.108037                 -0.687093 -0.773592   \n",
              "81   0.475615 -0.897510                  0.247783 -0.773592   \n",
              "119  2.061563 -0.897510                  0.247783 -0.773592   \n",
              "115 -0.275623  1.108037                 -0.105954 -0.773592   \n",
              "\n",
              "     ejection_fraction  high_blood_pressure  platelets  serum_sodium   \n",
              "184          -1.097586            -0.801179  -0.420499      0.103996  \\\n",
              "179           0.179716            -0.801179   0.292708      0.922398   \n",
              "213          -0.671818             1.241264  -0.123330     -1.805610   \n",
              "108           0.009409            -0.801179   0.589878     -0.987207   \n",
              "282          -0.671818            -0.801179  -0.468047     -2.351211   \n",
              "..                 ...                  ...        ...           ...   \n",
              "25            0.009409            -0.801179  -1.252575      2.013601   \n",
              "206           0.179716            -0.801179  -0.337292      1.195199   \n",
              "81            1.031251            -0.801179   0.106775      0.103996   \n",
              "119           0.009409            -0.801179   0.106775     -0.714406   \n",
              "115           0.179716            -0.801179  -1.074273      0.649597   \n",
              "\n",
              "          sex   smoking  \n",
              "184 -0.719812  1.300804  \n",
              "179 -0.719812  1.300804  \n",
              "213  1.381575 -0.764508  \n",
              "108 -0.719812  1.300804  \n",
              "282 -0.719812  1.300804  \n",
              "..        ...       ...  \n",
              "25  -0.719812  1.300804  \n",
              "206  1.381575 -0.764508  \n",
              "81  -0.719812  1.300804  \n",
              "119  1.381575 -0.764508  \n",
              "115  1.381575 -0.764508  \n",
              "\n",
              "[181 rows x 10 columns]"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "my_seed = 42\n",
        "\n",
        "# Selecting target value and dropping unwanted columns\n",
        "\n",
        "y = df[\"serum_creatinine\"] \n",
        "X = df[df.columns.drop([\"DEATH_EVENT\"])]\n",
        "\n",
        "# Splitting data into train, test and validation sets\n",
        "X_train, X_test = train_test_split(X,test_size = 0.3, random_state = my_seed)\n",
        "X_test, X_valid = train_test_split(X_test, test_size = 0.3, random_state = my_seed)\n",
        "\n",
        "\n",
        "# Normalizing the dataset (Z-normalization)\n",
        "mean = X_train.mean()\n",
        "stddev = X_train.std()\n",
        "\n",
        "X_train=(X_train-mean)/(stddev)\n",
        "y_train= X_train[\"serum_creatinine\"]\n",
        "X_train = X_train[X_train.columns.drop([\"serum_creatinine\"])]\n",
        "\n",
        "X_test=(X_test-mean)/(stddev)\n",
        "y_test= X_test[\"serum_creatinine\"]\n",
        "X_test = X_test[X_test.columns.drop([\"serum_creatinine\"])]\n",
        "\n",
        "X_valid=(X_valid-mean)/(stddev)\n",
        "y_valid= X_valid[\"serum_creatinine\"]\n",
        "X_valid = X_valid[X_valid.columns.drop([\"serum_creatinine\"])]\n",
        "\n",
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvrGLGqVXv8q"
      },
      "source": [
        "### Activities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os7TMYsiYaDv"
      },
      "source": [
        "1. (0.5 points) Verify if there is any feature that has low correlation with the target variables. You can use the function [mutual_info_regression](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html) to check the importance of each feature. \n",
        "\n",
        "> *   Do we need all the features to predict the target value?\n",
        "> *   What happens if we drop the low correlation features?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "BMyo_8gvEpuK"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>-0.275623</td>\n",
              "      <td>-1.097586</td>\n",
              "      <td>-0.420499</td>\n",
              "      <td>0.103996</td>\n",
              "      <td>-0.719812</td>\n",
              "      <td>1.300804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>-0.526036</td>\n",
              "      <td>0.179716</td>\n",
              "      <td>0.292708</td>\n",
              "      <td>0.922398</td>\n",
              "      <td>-0.719812</td>\n",
              "      <td>1.300804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>-1.110333</td>\n",
              "      <td>-0.671818</td>\n",
              "      <td>-0.123330</td>\n",
              "      <td>-1.805610</td>\n",
              "      <td>1.381575</td>\n",
              "      <td>-0.764508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>0.141731</td>\n",
              "      <td>0.009409</td>\n",
              "      <td>0.589878</td>\n",
              "      <td>-0.987207</td>\n",
              "      <td>-0.719812</td>\n",
              "      <td>1.300804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>-1.611159</td>\n",
              "      <td>-0.671818</td>\n",
              "      <td>-0.468047</td>\n",
              "      <td>-2.351211</td>\n",
              "      <td>-0.719812</td>\n",
              "      <td>1.300804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1.560738</td>\n",
              "      <td>0.009409</td>\n",
              "      <td>-1.252575</td>\n",
              "      <td>2.013601</td>\n",
              "      <td>-0.719812</td>\n",
              "      <td>1.300804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>-1.778101</td>\n",
              "      <td>0.179716</td>\n",
              "      <td>-0.337292</td>\n",
              "      <td>1.195199</td>\n",
              "      <td>1.381575</td>\n",
              "      <td>-0.764508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>0.475615</td>\n",
              "      <td>1.031251</td>\n",
              "      <td>0.106775</td>\n",
              "      <td>0.103996</td>\n",
              "      <td>-0.719812</td>\n",
              "      <td>1.300804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>2.061563</td>\n",
              "      <td>0.009409</td>\n",
              "      <td>0.106775</td>\n",
              "      <td>-0.714406</td>\n",
              "      <td>1.381575</td>\n",
              "      <td>-0.764508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>-0.275623</td>\n",
              "      <td>0.179716</td>\n",
              "      <td>-1.074273</td>\n",
              "      <td>0.649597</td>\n",
              "      <td>1.381575</td>\n",
              "      <td>-0.764508</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>181 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          age  ejection_fraction  platelets  serum_sodium       sex   smoking\n",
              "184 -0.275623          -1.097586  -0.420499      0.103996 -0.719812  1.300804\n",
              "179 -0.526036           0.179716   0.292708      0.922398 -0.719812  1.300804\n",
              "213 -1.110333          -0.671818  -0.123330     -1.805610  1.381575 -0.764508\n",
              "108  0.141731           0.009409   0.589878     -0.987207 -0.719812  1.300804\n",
              "282 -1.611159          -0.671818  -0.468047     -2.351211 -0.719812  1.300804\n",
              "..        ...                ...        ...           ...       ...       ...\n",
              "25   1.560738           0.009409  -1.252575      2.013601 -0.719812  1.300804\n",
              "206 -1.778101           0.179716  -0.337292      1.195199  1.381575 -0.764508\n",
              "81   0.475615           1.031251   0.106775      0.103996 -0.719812  1.300804\n",
              "119  2.061563           0.009409   0.106775     -0.714406  1.381575 -0.764508\n",
              "115 -0.275623           0.179716  -1.074273      0.649597  1.381575 -0.764508\n",
              "\n",
              "[181 rows x 6 columns]"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "# Feature selection.\n",
        "correlation = mutual_info_regression(X_train, y_train, random_state= my_seed)\n",
        "idx = np.array([]).astype(int)\n",
        "for i in range(len(correlation)):\n",
        "    if correlation[i] <= 0.02:\n",
        "        idx = np.append(idx, i)\n",
        "\n",
        "# Columns with low correlation are dropped\n",
        "X_train = X_train.drop(X_train.columns[idx], axis = 1)\n",
        "X_test = X_test.drop(X_test.columns[idx], axis = 1)\n",
        "X_valid = X_valid.drop(X_valid.columns[idx], axis = 1)\n",
        "X_train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX3PMBcOazAy"
      },
      "source": [
        "> What are the conclusions? (1-2 paragraphs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analisando a correlação entre o valor alvo e as features, constata-se que há algumas features cujo valor aparentam não influenciar, ou têm uma influência muito baixa no valor objetivo. Com isso, é razoável eliminar essas features de baixa correlação para que elas não sejam levadas em consideração no treinamento do modelo. \n",
        "\n",
        "Esse procedimento de feature selection pode ser benéfico, pois, dessa forma, serão ponderadas apenas as features de maior impacto na predição do valor alvo, o que, a princípio deve levar a um resultado mais preciso e coerente. Além disso, o próprio processo de treinamento se torna mais eficiente, uma vez que há uma diminuição no volume de dados a ser analisado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVGywzmSZxr7"
      },
      "source": [
        "2. (2.0 points) Perform Linear Regression. You should implement your solution and compare it with ```sklearn.linear_model.SGDRegressor``` (linear model fitted by minimizing a regularized empirical loss with SGD, http://scikit-learn.org)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "Oq4uQfV9G25g"
      },
      "outputs": [],
      "source": [
        "def MSE(Y,H):\n",
        "  e = (Y - H) ** 2\n",
        "  e = np.sum(e)\n",
        "  return e / Y.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "qK67IAeJGVRm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On training set: MSE = 0.801\n",
            "On test set: MSE = 1.045\n",
            "(w0 = 0.000,\n",
            " w1 = 0.212,\n",
            " w2 = -0.162,\n",
            " w3 = -0.027,\n",
            " w4 = -0.291,\n",
            " w5 = -0.030,\n",
            " w6 = 0.010)\n"
          ]
        }
      ],
      "source": [
        "class LinearRegression():\n",
        "  def __init__(self, learning_rate=0.01, max_iter=1000):\n",
        "    self.max_iter         = max_iter\n",
        "    self.learning_rate    = learning_rate\n",
        "    self.weights          = None\n",
        "    self.bias             = None\n",
        "    self.tolerance        = 1e-5\n",
        "    self.cost             = None\n",
        "\n",
        "  def predict(self, X):\n",
        "    pred = np.array([])\n",
        "    for x in X.to_numpy():\n",
        "      pred = np.append(pred, self.bias + np.sum((self.weights * x)))\n",
        "    return pred\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    # Initialize vector to save the costs\n",
        "    costs = np.array([]) \n",
        "    # Initializes weights, bias and current cost\n",
        "    if self.weights == None:\n",
        "      self.weights = np.array([0.0 for _ in range(X.shape[1])]).astype(np.float64)\n",
        "    if self.bias == None:\n",
        "      self.bias = 0.0\n",
        "    if self.cost == None:\n",
        "      self.cost = MSE(y, self.predict(X))\n",
        "    prediction = self.predict(X)\n",
        "      \n",
        "    # Loop for updating weights and bias\n",
        "    for _ in range(self.max_iter):\n",
        "      self.bias = self.bias - (self.learning_rate * (1/y.size) * np.sum(prediction - y))\n",
        "      for i in range(len(self.weights)):\n",
        "        self.weights[i] = self.weights[i] - (self.learning_rate * (1/y.size) * np.sum((prediction - y) * (X.to_numpy())[:,i]))\n",
        "\n",
        "      prediction = self.predict(X)\n",
        "\n",
        "      # If the difference between current error and previous error is lower \n",
        "      # than the tolerance then the algorithm can stop\n",
        "      if abs(MSE(y, prediction) - self.cost) < self.tolerance:\n",
        "        break\n",
        "      # If MSE starts to increase, it has already surpassed its lowest point\n",
        "      if MSE(y, prediction) > self.cost:\n",
        "        break\n",
        "      else:\n",
        "        self.cost = MSE(y, prediction)\n",
        "        costs = np.append(costs, self.cost)\n",
        "    return self.weights, costs\n",
        "  \n",
        "# Create linear regression object\n",
        "\n",
        "model = LinearRegression(learning_rate=0.02, max_iter=1000)\n",
        "\n",
        "# Train the model using the training set\n",
        "\n",
        "costs = model.fit(X_train, y_train)[1]\n",
        "\n",
        "# Resulting MSE\n",
        "print(f\"On training set: MSE = {round(MSE(y_train, model.predict(X_train)), 3)}\")\n",
        "\n",
        "print(f\"On test set: MSE = {round(MSE(y_test, model.predict(X_test)), 3)}\")\n",
        "\n",
        "# The obtained weights during training\n",
        "print(\"(w0 = %2.3f\" % model.bias, end = \"\")\n",
        "for i in range(X_train.shape[1]):\n",
        "    print(\",\\n w%d = %2.3f\" % (i+1, model.weights[i]), end = \"\")\n",
        "print(\")\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "AzPTyI1EG9hY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On training set: MSE = 0.801\n",
            "On test set: MSE = 1.046\n",
            "(w0 = 0.002,\n",
            " w1 = 0.215,\n",
            " w2 = -0.163,\n",
            " w3 = -0.025,\n",
            " w4 = -0.292,\n",
            " w5 = -0.028,\n",
            " w6 = 0.011)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "scikit_model = SGDRegressor(random_state=42)\n",
        "scikit_model.fit(X_train, y_train)\n",
        "y_pred_train = scikit_model.predict(X_train)\n",
        "y_pred_test = scikit_model.predict(X_test)\n",
        "\n",
        "print(f\"On training set: MSE = {round(MSE(y_train, y_pred_train),3)}\")\n",
        "print(f\"On test set: MSE = {round(MSE(y_test, y_pred_test),3)}\")\n",
        "\n",
        "print(\"(w0 = %2.3f\" % scikit_model.intercept_, end = \"\")\n",
        "for i in range(X_train.shape[1]):\n",
        "    print(\",\\n w%d = %2.3f\" % (i+1, scikit_model.coef_[i]), end = \"\")\n",
        "print(\")\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXTk6P4MbbnH"
      },
      "source": [
        "> What are the conclusions? (1-2 paragraphs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O procedimento adotado na implementação da Regressão Linear consistiu na atualização dos pesos pela fórmula da derivada parcial em relação a cada peso (conforme o modelo apresentado em aula do algoritmo padrão do Gradiente Descendente). Isso fez com que o treinamento se tornasse mais lento, especialmente quando comparado com a velocidade do Stochastic Gradient Descent do scikit-learn. Por outro lado, o modelo implementado apresenta a vantagem de sempre apresentar os mesmos resultados com consistência, uma vez que não depende de fatores aleatórios, como é o caso do Stochastic Gradient Descent.\n",
        "\n",
        "Em relação aos resultados, temos que o erro (MSE) de ambas soluções foram muito semelhantes. Os pesos (```w0``` a ```w6```) obtidos também estão relativamente próximos um do outro, o que indica uma consistência entre as duas soluções, além de fornecer uma certa validação para o modelo implementado manualmente. Além disso, os valores de MSE para o treinamento e teste estão relativamente próximos, o que indica uma coerência do modelo treinado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx-ZsOBzg70n"
      },
      "source": [
        "3. (0.5 points) Plot the cost function vs. number of epochs in the training/validation set and analyze the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "oQrJx9YshBqX"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAGwCAYAAABSN5pGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVjUlEQVR4nO3deVyU1eI/8M8wCoMLILIvipKFKxgqoalUJOUNNbC8ZoqamgUm0qIWiuFNzFuKa956lXZd0lS0e7Xwp4imuSW4fE0lRRNFFtEARVlkzu+PuTMxrDMwwyx83q/XvHSe58zznKPGfDrPWSRCCAEiIiIiUrEwdAWIiIiIjA0DEhEREVE1DEhERERE1TAgEREREVXDgERERERUDQMSERERUTUMSERERETVtDJ0BUyVXC7HrVu30L59e0gkEkNXh4iIiDQghMC9e/fg5uYGC4u6+4kYkBrp1q1b8PT0NHQ1iIiIqBFu3LgBDw+POs8zIDVS+/btASj+gG1sbAxcGyIiItJEcXExPD09Vd/jdWFAaiTlYzUbGxsGJCIiIhPT0PAYDtImIiIiqoYBiYiIiKgaBiQiIiKiahiQiIiIiKphQCIiIiKqhgGJiIiIqBoGJCIiIqJqGJCIiIiIqmFAIiIiIqqGK2kbkcpK4PBhICcHcHUFBg8GpFJD14qIiKjlYUAyEklJwMyZwM2bfx3z8ACWLwfCwgxXLyIiopaIj9iMQFISMHq0ejgCgOxsxfGkJMPUi4iIqKViQDKwykpFz5EQNc8pj0VHK8oRERFR82BAMrDDh2v2HFUlBHDjhqIcERERNQ8GJAPLydFtOSIiImo6BiQDc3XVbTkiIiJqOgYkAxs8WDFbTSKp/bxEAnh6KsoRERFR82BAMjCpVDGVH6gZkpTvExO5HhIREVFzYkAyAmFhwPbtgLu7+nEPD8VxroNERETUvLhQpJEICwNGjuRK2kRERMaAAcmISKVAUJCha0FERER8xEZERERUDQMSERERUTUMSERERETVMCARERERVcNB2kaqspIz2oiIiAyFAckIJSUBM2eqb2Lr4aFYUJJrIhEREekfH7EZmaQkYPRo9XAEANnZiuNJSYapFxERUUvCgGREKisVPUdC1DynPBYdrShHRERE+mPwgLR69Wp4eXlBJpMhICAAJ0+erLNsRUUF4uPj4e3tDZlMBl9fXyQnJ6uV8fLygkQiqfGKjIxUlQkKCqpxfvr06Xpro6YOH67Zc1SVEMCNG4pyREREpD8GDUhbt25FTEwM4uLikJ6eDl9fX4SEhCA/P7/W8rGxsfjXv/6FlStX4sKFC5g+fTpefvllnD59WlXm119/RU5Ojuq1b98+AMArr7yidq2pU6eqlVuyZIn+GqqhnBzdliMiIqLGMWhAWrp0KaZOnYpJkyahR48eWLt2Ldq0aYNvvvmm1vIbNmzAhx9+iOHDh6Nr16546623MHz4cHz++eeqMo6OjnBxcVG9du/eDW9vbwwdOlTtWm3atFErZ2Njo9e2asLVVbfliIiIqHEMFpDKy8uRlpaG4ODgvypjYYHg4GAcO3as1s+UlZVBJpOpHbO2tsaRI0fqvMfGjRsxefJkSCQStXObNm2Cg4MDevXqhblz5+LBgwf11resrAzFxcVqL10bPFgxW61aVVUkEsDTU1GOiIiI9MdgAamgoACVlZVwdnZWO+7s7Izc3NxaPxMSEoKlS5fi8uXLkMvl2LdvH5KSkpBTxzOnXbt2obCwEBMnTlQ7/tprr2Hjxo1ITU3F3LlzsWHDBrz++uv11jchIQG2traql6enp+aN1ZBUqpjKD9QMScr3iYlcD4mIiEjfDD5IWxvLly9Ht27d4OPjA0tLS0RFRWHSpEmwsKi9GV9//TVefPFFuLm5qR2fNm0aQkJC0Lt3b4wbNw7//ve/sXPnTmRmZtZ577lz56KoqEj1unHjhk7bphQWBmzfDri7qx/38FAc5zpIRERE+mewhSIdHBwglUqRl5endjwvLw8uLi61fsbR0RG7du1CaWkp7ty5Azc3N8yZMwddu3atUfb69evYv38/kjRYOCggIAAAcOXKFXh7e9daxsrKClZWVg1eSxfCwoCRI7mSNhERkaEYrAfJ0tIS/v7+SElJUR2Ty+VISUlBYGBgvZ+VyWRwd3fHo0ePsGPHDowcObJGmXXr1sHJyQl/+9vfGqzLmTNnAACuRjT6WSoFgoKAsWMVvzIcERERNR+DbjUSExODiIgI9OvXDwMGDEBiYiJKSkowadIkAMCECRPg7u6OhIQEAMCJEyeQnZ0NPz8/ZGdnY8GCBZDL5fjggw/UriuXy7Fu3TpERESgVSv1JmZmZmLz5s0YPnw4OnbsiHPnzmHWrFkYMmQI+vTp0zwNJyIiIqNm0IA0ZswY3L59G/Pnz0dubi78/PyQnJysGridlZWlNr6otLQUsbGxuHr1Ktq1a4fhw4djw4YNsLOzU7vu/v37kZWVhcmTJ9e4p6WlJfbv368KY56enggPD0dsbKxe20pERESmQyJEbRtbUEOKi4tha2uLoqIio1hDiYiIiBqm6fe3QXuQSDOVlRywTURE1JwYkIxcUpJiA9uqe7R5eCjWS+KUfyIiIv0wqXWQWpqkJGD06Job2GZnK45rsIIBERERNQIDkpGqrFT0HNU2Qkx5LDpaUY6IiIh0iwHJSB0+XLPnqCohgBs3FOWIiIhItxiQjFQd28s1uhwRERFpjgHJSGm6qLcRLf5NRERkNhiQjNTgwYrZahJJ7eclEsDTU1GOiIiIdIsByUhJpYqp/EDNkKR8n5jI9ZCIiIj0gQHJiIWFAdu3A+7u6sc9PBTHuQ4SERGRfnChSCMXFgaMHMmVtImIiJoTA5IJkEqBoCBD14KIiKjl4CM2IiIiomoYkIiIiIiq4SM2E1NZyfFIRERE+saAZEKSkhT7s1XdgsTDQ7EcAGe0ERER6Q4fsZmIpCRg9Oia+7NlZyuOJyUZpl5ERETmiAHJBFRWKnqOhKh5TnksOlpRjoiIiJqOAckEHD5cs+eoKiGAGzcU5YiIiKjpGJBMQE6ObssRERFR/RiQTICrq27LERERUf0YkEzA4MGK2WrVN61VkkgAT09FOSIiImo6BiQTIJUqpvIDNUOS8n1iItdDIiIi0hUGJBMRFgZs3w64u6sf9/BQHOc6SERERLrDhSJNSFgYMHIkV9ImIiLSNwYkEyOVAkFBhq4FERGReeMjNiIiIqJqGJCIiIiIquEjNhNWWcnxSERERPrAgGSikpIU+7NV3YLEw0OxHABntBERETUNH7GZoKQkYPTomvuzZWcrjiclGaZeRERE5oIBycRUVip6joSoeU55LDpaUY6IiIgahwHJxBw+XLPnqCohgBs3FOWIiIiocRiQTExOjm7LERERUU0MSCbG1VW35YiIiKgmgwek1atXw8vLCzKZDAEBATh58mSdZSsqKhAfHw9vb2/IZDL4+voiOTlZrcyCBQsgkUjUXj4+PmplSktLERkZiY4dO6Jdu3YIDw9HXl6eXtqna4MHK2arVd+0VkkiATw9FeWIiIiocQwakLZu3YqYmBjExcUhPT0dvr6+CAkJQX5+fq3lY2Nj8a9//QsrV67EhQsXMH36dLz88ss4ffq0WrmePXsiJydH9Tpy5Ija+VmzZuG///0vtm3bhkOHDuHWrVsIM5G58VKpYio/UDMkKd8nJnI9JCIioqaQCFHbfKjmERAQgP79+2PVqlUAALlcDk9PT8yYMQNz5sypUd7NzQ0fffQRIiMjVcfCw8NhbW2NjRs3AlD0IO3atQtnzpyp9Z5FRUVwdHTE5s2bMXr0aADApUuX0L17dxw7dgxPPfVUrZ8rKytDWVmZ6n1xcTE8PT1RVFQEGxubRrW/KWpbB8nTUxGOTCTrERERNbvi4mLY2to2+P1tsB6k8vJypKWlITg4+K/KWFggODgYx44dq/UzZWVlkMlkasesra1r9BBdvnwZbm5u6Nq1K8aNG4esrCzVubS0NFRUVKjd18fHB506darzvgCQkJAAW1tb1cvT01Or9upaWBjwxx9AaiqwebPi12vXGI6IiIh0wWABqaCgAJWVlXB2dlY77uzsjNzc3Fo/ExISgqVLl+Ly5cuQy+XYt28fkpKSkFNlylZAQADWr1+P5ORkfPHFF7h27RoGDx6Me/fuAQByc3NhaWkJOzs7je8LAHPnzkVRUZHqdePGjUa2XHekUiAoCBg7VvErH6sRERHphkltNbJ8+XJMnToVPj4+kEgk8Pb2xqRJk/DNN9+oyrz44ouq3/fp0wcBAQHo3Lkzvv/+e7zxxhuNvreVlRWsrKyaVH8iIiIyDQbrQXJwcIBUKq0xeywvLw8uLi61fsbR0RG7du1CSUkJrl+/jkuXLqFdu3bo2rVrnfexs7PD448/jitXrgAAXFxcUF5ejsLCQo3vawoqK4GDB4HvvlP8ypW0iYiIGs9gAcnS0hL+/v5ISUlRHZPL5UhJSUFgYGC9n5XJZHB3d8ejR4+wY8cOjBw5ss6y9+/fR2ZmJlz/tzCQv78/WrdurXbfjIwMZGVlNXhfY5WUBHh5Ac88A7z2muJXLy/uyUZERNRYBn3EFhMTg4iICPTr1w8DBgxAYmIiSkpKMGnSJADAhAkT4O7ujoSEBADAiRMnkJ2dDT8/P2RnZ2PBggWQy+X44IMPVNd87733EBoais6dO+PWrVuIi4uDVCrF2LFjAQC2trZ44403EBMTA3t7e9jY2GDGjBkIDAyscwabMVNuXFt9LqJy49rt2zlwm4iISFsGDUhjxozB7du3MX/+fOTm5sLPzw/JycmqgdtZWVmwsPirk6u0tBSxsbG4evUq2rVrh+HDh2PDhg1qA65v3ryJsWPH4s6dO3B0dMTTTz+N48ePw9HRUVVm2bJlsLCwQHh4OMrKyhASEoI1a9Y0W7t1paGNayUSxca1I0dyADcREZE2DLoOkinTdB0FfTp4UPE4rSGpqYpZbkRERC2d0a+DRE3HjWuJiIj0gwHJhHHjWiIiIv1gQDJh3LiWiIhIPxiQTBg3riUiItIPBiQTFxammMrv7q5+3MODU/yJiIgay6S2GqHahYUppvIfPqwYkO3qqnisxp4jIiKixmFAMhPKjWuJiIio6RiQzFBlJXuTiIiImoIBycwkJSlW1755869jHh6Kwdwcj0RERKQZDtI2I8p92aqGI+Cvfdm4eS0REZFmGJDMREP7sgGKfdkqK5u1WkRERCaJAclMHD5cs+eoKiGAGzcU5YiIiKh+DEhmgvuyERER6Q4DkpngvmxERES6w4BkJrgvGxERke4wIJkJ7stGRESkOwxIZoT7shEREekGF4o0M9yXjYiIqOkYkMwQ92UjIiJqGgYkM8d92YiIiLTHgGTGuC8bERFR43CQtpnivmxERESNx4BkhrgvGxERUdMwIJkh7stGRETUNAxIZoj7shERETUNA5IZ4r5sRERETcOAZIa4LxsREVHTMCCZIe7LRkRE1DQMSGaK+7IRERE1HheKNGPcl42IiKhxtA5I165dw+HDh3H9+nU8ePAAjo6O6Nu3LwIDAyGTyfRRR2oC5b5syi1Hvv+eQYmIiKghGgekTZs2Yfny5Th16hScnZ3h5uYGa2tr3L17F5mZmZDJZBg3bhxmz56Nzp0767POpCVuOUJERKQdjcYg9e3bFytWrMDEiRNx/fp15OTkIC0tDUeOHMGFCxdQXFyMH374AXK5HP369cO2bdv0XW/SELccISIi0p5EiNo2pFC3d+9ehISEaHTBO3fu4I8//oC/v3+TK2fMiouLYWtri6KiItjY2Bi6OrWqrAS8vOpeVVsiUfQkXbvGx21ERNQyaPr9rVEPkqbhCAA6duyoVThavXo1vLy8IJPJEBAQgJMnT9ZZtqKiAvHx8fD29oZMJoOvry+Sk5PVyiQkJKB///5o3749nJycMGrUKGRkZKiVCQoKgkQiUXtNnz5d4zqbCm45QkRE1DgaT/P//vvvUV5ernp/8+ZNyOVy1fsHDx5gyZIlWt1869atiImJQVxcHNLT0+Hr64uQkBDk5+fXWj42Nhb/+te/sHLlSly4cAHTp0/Hyy+/jNOnT6vKHDp0CJGRkTh+/Dj27duHiooKDBs2DCUlJWrXmjp1KnJyclQvbetuCrjlCBERUeNo9IgNAKRSKXJycuDk5AQAsLGxwZkzZ9C1a1cAQF5eHtzc3FCpxRbxAQEB6N+/P1atWgUAkMvl8PT0xIwZMzBnzpwa5d3c3PDRRx8hMjJSdSw8PBzW1tbYuHFjrfe4ffs2nJyccOjQIQwZMgSAogfJz88PiYmJGte1OlN4xHbwIPDMMw2XS01VzHQjIiIydzp9xAYA1XOUhrmqTuXl5UhLS0NwcPBflbGwQHBwMI4dO1brZ8rKymosJWBtbY0jR47UeZ+ioiIAgL29vdrxTZs2wcHBAb169cLcuXPx4MGDeutbVlaG4uJitZex45YjREREjWOwlbQLCgpQWVkJZ2dntePOzs7Izc2t9TMhISFYunQpLl++DLlcjn379iEpKQk5dTwjksvliI6OxqBBg9CrVy/V8ddeew0bN25Eamoq5s6diw0bNuD111+vt74JCQmwtbVVvTw9PbVscfPjliNERESNY1JbjSxfvhzdunWDj48PLC0tERUVhUmTJsHCovZmREZG4vz589iyZYva8WnTpiEkJAS9e/fGuHHj8O9//xs7d+5EZmZmnfeeO3cuioqKVK8bN27otG36wi1HiIiItKfVStp79+6Fra0tAEXvTEpKCs6fPw8AKCws1OrGDg4OkEqlyMvLUzuel5cHFxeXWj/j6OiIXbt2obS0FHfu3IGbmxvmzJmjGgdVVVRUFHbv3o2ff/4ZHh4e9dYlICAAAHDlyhV4e3vXWsbKygpWVlaaNM3ocMsRIiIi7WgVkCIiItTev/nmm2rvJXUNdqmFpaUl/P39kZKSglGjRgH4K3RFRUXV+1mZTAZ3d3dUVFRgx44dePXVV1XnhBCYMWMGdu7ciYMHD6JLly4N1uXMmTMAAFdXV43rb2qUW44Af207wrBERERUO40DUtUp/boSExODiIgI9OvXDwMGDEBiYiJKSkowadIkAMCECRPg7u6OhIQEAMCJEyeQnZ0NPz8/ZGdnY8GCBZDL5fjggw9U14yMjMTmzZvxww8/oH379qrxTLa2trC2tkZmZiY2b96M4cOHo2PHjjh37hxmzZqFIUOGoE+fPjpvo7HhtiNEREQN03qzWl0aM2YMbt++jfnz5yM3Nxd+fn5ITk5WDdzOyspSG19UWlqK2NhYXL16Fe3atcPw4cOxYcMG2NnZqcp88cUXABRT+atat24dJk6cCEtLS+zfv18Vxjw9PREeHo7Y2Fi9t9fQlNuOVJ+AqNx2hGOSiIiIFDReB+n3339HYWEhBgwYoDqWkpKCf/zjHygpKcGoUaPw4Ycf6q2ixsYU1kGqituOEBER6WEdpNmzZ2P37t2q99euXUNoaCgsLS0RGBiIhISEJi28SPrFbUeIiIg0p/EjtlOnTqmN9dm0aRMef/xx7N27FwDQp08frFy5EtHR0TqvJDUdtx0hIiLSnMY9SAUFBWrT5VNTUxEaGqp6HxQUhD/++EOnlSPd0XSCnhlP5CMiItKYxgHJ3t5etWK1XC7HqVOn8NRTT6nOl5eXN3n7EdIfbjtCRESkOY0DUlBQEBYuXIgbN24gMTERcrlcbabYhQsX4OXlpYcqki5w2xEiIiLNaTwG6ZNPPsHzzz+Pzp07QyqVYsWKFWjbtq3q/IYNG/Dss8/qpZKkG8ptR2pbBykxkVP8iYiIlDSe5g8Ajx49wm+//QZHR0e4ubmpnTt79iw8PDzQsWNHnVfSGJnaNP+qqq6k7eSkOJafz1W1iYjI/Gn6/a1VQKK/mHJAUuKq2kRE1NJo+v2t8SO2+Ph4jcrNnz9f00uSAXFVbSIiorpp3INkYWEBNzc3ODk51TlbTSKRID09XacVNFam3IPEVbWJiKil0nkP0osvvogDBw6gX79+mDx5Ml566SW1fdLIdGizqna1Le2IiIhaBI0Tzp49e5CZmYmAgAC8//77cHd3x+zZs5GRkaHP+pEecFVtIiKi+mnVBeTm5oa5c+ciIyMDW7duRX5+Pvr3749Bgwbh4cOH+qoj6RhX1SYiIqqfxo/Yquvfvz/++OMPXLhwAadPn0ZFRQWsra11WTfSE+Wq2tnZNQdpA3+NQeKq2kRE1FJpPYjo2LFjmDp1KlxcXLBy5UpERETg1q1bJjdQuSXjqtpERET10zggLVmyBD169MDIkSPRrl07HD58GL/++ivefvtt2NnZ6bGKpA/KVbXd3dWPOzgo1kayt1fMdiMiImqJtJrm36lTJ7z00kuwtLSss9zSpUt1VjljZsrT/KtSrqr9ww/Apk3A7dt/neOikUREZG50Ps1/yJAhkEgk+O233+osI6lrq3gyWlIpcPeuIghx0UgiIiIFbjXSSObUg8RFI4mIqKXQ9PubKz22cNosGklERNRSaBSQFi9ejAcPHmh0wRMnTmDPnj1NqhQ1Hy4aSUREVJNGAenChQvo3Lkz3n77bfz000+4XWUk76NHj3Du3DmsWbMGAwcOxJgxY9C+fXu9VZh0i4tGEhER1aTxGKSzZ89i1apV2L59O4qLiyGVSmFlZaXqWerbty+mTJmCiRMnQiaT6bXSxsDcxiA1tGgkxyAREZE50PT7W+tB2nK5HOfOncP169fx8OFDODg4wM/PDw4ODk2utCkxl4AEAElJitlqgHpIUk5K5Cw2IiIyF3oLSKRgTgEJUISkmTPVB2x7eipW1GY4IiIic8GApGfmFpCAvxaNzMkBnJwUx/LzFeOPBg/mIzYiIjJ9Ol8oksyfVAoEBSl6kyZOVO9N4qraRETUknAdJFKjHI9UfW0k5araSUmGqRcREVFzYkAilcpKxTik2h66Ko9FR3MTWyIiMn8MSKTCVbWJiIgUtB6DVFJSgsWLFyMlJQX5+fmQy+Vq569evaqzylHz4qraRERECloHpClTpuDQoUMYP348XF1dIVEulkMmj6tqExERKWgdkH766Sfs2bMHgwYN0kd9yIAGD1bMVmtoVe3Bg5u/bkRERM1J6zFIHTp0gL29vT7qQgYmlSqm8gN/raJdlRDAlCnNWyciIiJD0DogLVy4EPPnz1ftwUbmJSxMsbWIu3vt5+PiFHu3cbo/ERGZM60D0ueff469e/fC2dkZvXv3xpNPPqn20tbq1avh5eUFmUyGgIAAnDx5ss6yFRUViI+Ph7e3N2QyGXx9fZGcnKz1NUtLSxEZGYmOHTuiXbt2CA8PR15entZ1N1dhYcAffwAff1z7ea6JRERE5k7rMUijRo3S2c23bt2KmJgYrF27FgEBAUhMTERISAgyMjLgpNzroorY2Fhs3LgRX331FXx8fLB37168/PLLOHr0KPr27avxNWfNmoU9e/Zg27ZtsLW1RVRUFMLCwvDLL7/orG3m4Kuvaj8uhOIRXHQ0MHIktyAhIiIzJAxowIABIjIyUvW+srJSuLm5iYSEhFrLu7q6ilWrVqkdCwsLE+PGjdP4moWFhaJ169Zi27ZtqjIXL14UAMSxY8c0rntRUZEAIIqKijT+jClJTRVCEYXqf6WmGrqmREREmtP0+7vRC0WmpaVh48aN2LhxI06fPq3158vLy5GWlobg4GDVMQsLCwQHB+PYsWO1fqasrAwymUztmLW1NY4cOaLxNdPS0lBRUaFWxsfHB506darzvsp7FxcXq73MGddEIiKilkzrR2z5+fn4+9//joMHD8LOzg4AUFhYiGeeeQZbtmyBo6OjRtcpKChAZWUlnJ2d1Y47Ozvj0qVLtX4mJCQES5cuxZAhQ+Dt7Y2UlBQkJSWh8n97X2hyzdzcXFhaWqrqXrVMbm5unfVNSEjAx3UNyjFDXBOJiIhaMq17kGbMmIF79+7ht99+w927d3H37l2cP38excXFeOedd/RRR5Xly5ejW7du8PHxgaWlJaKiojBp0iRYWOh/x5S5c+eiqKhI9bpx44be72lIyjWR6loHVCIBPD25JhIREZknrZNFcnIy1qxZg+7du6uO9ejRA6tXr8ZPP/2k8XUcHBwglUprzB7Ly8uDi4tLrZ9xdHTErl27UFJSguvXr+PSpUto164dunbtqvE1XVxcUF5ejsLCQo3vCwBWVlawsbFRe5mz+tZEUr5PTOQAbSIiMk9aByS5XI7WrVvXON66desa+7LVx9LSEv7+/khJSVG7dkpKCgIDA+v9rEwmg7u7Ox49eoQdO3Zg5MiRGl/T398frVu3ViuTkZGBrKysBu/b0tS1JpKDAzBzJmBvD/zv6SYREZF50Xb094gRI8SQIUNEdna26tjNmzfF0KFDxahRo7S61pYtW4SVlZVYv369uHDhgpg2bZqws7MTubm5Qgghxo8fL+bMmaMqf/z4cbFjxw6RmZkpfv75Z/Hss8+KLl26iD///FPjawohxPTp00WnTp3EgQMHxKlTp0RgYKAIDAzUqu7mPoutqkePFLPVoqOFcHRUn8Xm4SHEjh2GriEREZFmNP3+1nqQ9qpVqzBixAh4eXnB09MTAHDjxg306tULGzdu1OpaY8aMwe3btzF//nzk5ubCz88PycnJqkHWWVlZauOLSktLERsbi6tXr6Jdu3YYPnw4NmzYoDbguqFrAsCyZctgYWGB8PBwlJWVISQkBGvWrNH2j6LFkEqBu3cVj9yq79GmXDRy+3ZFjxMREZE5kAhR27ak9RNCYP/+/aqZYd27d1ebNt8SFBcXw9bWFkVFRWY/HqmyUrG9yM2btZ9XbmJ77RrHJBERkXHT9Pu7UQGJWlZAOngQeOaZhsulpgJBQfquDRERUeNp+v2t0SO2FStWYNq0aZDJZFixYkW9ZfU91Z+aHxeNJCKilkajHqQuXbrg1KlT6NixI7p06VL3xSQSXL16VacVNFbsQaqJPUhERGTs+IhNz1pSQFKOQcrOrjlIG+AYJCIiMh2afn9rvQ5SfHw8Hjx4UOP4w4cPER8fr+3lyATUt2gkoAhNU6Y0b52IiIj0SeseJKlUipycHDg5Oakdv3PnDpycnFT7opm7ltSDpJSUpFggsq7ZbB4eiiDF6f5ERGSs9NaDJISApJZuhLNnz8Le3l7by5EJCQsD/vgDqGvPXuWaSElJzVotIiIindN4ocgOHTpAIpFAIpHg8ccfVwtJlZWVuH//PqZPn66XSpJx+eqr2o8LoXgEFx0NjBzJ8UhERGS6NA5IiYmJEEJg8uTJ+Pjjj2Fra6s6Z2lpCS8vL+5l1gIcPlz3IzZAEZJu3FCU44w2IiIyVRoHpIiICACKKf+DBg1Cq1Za71JCZoBrIhERUUug9RikkpISpKSk1Di+d+9e/PTTTzqpFBkvV1fdliMiIjJGWgekOXPm1DpTTQiBOXPm6KRSZLwGD1bMVqttur+SoyMwcGDz1YmIiEjXtA5Ily9fRo8ePWoc9/HxwZUrV3RSKTJeDa2JBAC3bwPe3pzNRkREpkvrgGRra1vrdiJXrlxB27ZtdVIpMm5hYcD27YC7e91lOOWfiIhMmdYBaeTIkYiOjkZmZqbq2JUrV/Duu+9ixIgROq0cGa+wMCAzU/E4rTbK5UejoxVblRAREZkSrQPSkiVL0LZtW/j4+KBLly7o0qULunfvjo4dO+Kzzz7TRx3JSB09qnicVpeqU/6JiIhMidZz9W1tbXH06FHs27cPZ8+ehbW1Nfr06YMhQ4boo35kxDjln4iIzFWjFjOSSCQYNmwYhg0bpuv6kAnhlH8iIjJXjQpIKSkpSElJQX5+PuRyudq5b775RicVI+OnnPKfnf3XmKPqPDwU5YiIiEyJ1mOQPv74YwwbNgwpKSkoKCjAn3/+qfailkOTKf8PHwI//NB8dSIiItIFiRB1/b9/7VxdXbFkyRKMHz9eX3UyCcXFxbC1tUVRURFsbGwMXR2DSkoCpk0D7typeU4ZnLZvV8x8IyIiMiRNv7+17kEqLy/HQC6TTFWMHAlYW9d+jtP9iYjIFGkdkKZMmYLNmzfroy5kog4fBm7erPs8p/sTEZGp0XqQdmlpKb788kvs378fffr0QevWrdXOL126VGeVI9PA6f5ERGRutA5I586dg5+fHwDg/Pnzauck9e1gSmaL0/2JiMjcaB2QUlNT9VEPMmGaTPd3dAQ4dI2IiEyF1mOQiKrTZLr/7duAtzc3ryUiItOg9TT/Z555pt5HaQcOHGhypUwBp/nXlJQEzJxZ94BtTvknIiJD09s0fz8/P/j6+qpePXr0QHl5OdLT09G7d+8mVZpMW1gYkJmpeJxWG075JyIiU6H1GKRly5bVenzBggW4f/9+kytEpu3oUcXjtLpUnfIfFNRs1SIiItKKzsYgvf7669yHjTjln4iIzILOAtKxY8cgk8l0dTkyUZzyT0RE5kDrR2xh1UbXCiGQk5ODU6dOYd68eTqrGJkmTvknIiJzoHUPkq2trdrL3t4eQUFB+PHHHxEXF6ePOpIJ4ZR/IiIyBxpN81+xYgWmTZsGmUyGrKwseHh4wMKiZS+hxGn+9eOUfyIiMkY6neYfExOD4uJiAECXLl1QUFCgm1oCWL16Nby8vCCTyRAQEICTJ0/WWz4xMRFPPPEErK2t4enpiVmzZqG0tFR13svLCxKJpMYrMjJSVSYoKKjG+enTp+usTcQp/0REZNo0GoPk5uaGHTt2YPjw4RBC4ObNm2qhpKpOnTppfPOtW7ciJiYGa9euRUBAABITExESEoKMjAw4OTnVKL9582bMmTMH33zzDQYOHIjff/8dEydOhEQiUW2S++uvv6Kyyjfu+fPn8fzzz+OVV15Ru9bUqVMRHx+vet+mTRuN602a4ZR/IiIyVRoFpNjYWMyYMQNRUVGQSCTo379/jTJCCEgkErVw0pClS5di6tSpmDRpEgBg7dq12LNnD7755hvMmTOnRvmjR49i0KBBeO211wAoeovGjh2LEydOqMo4VuuyWLx4Mby9vTF06FC1423atIGLi4vGdS0rK0NZWZnqvbJHjerGKf9ERGSqNHrENm3aNBQUFODs2bMQQmDfvn1IT09Xe50+fRrp6eka37i8vBxpaWkIDg7+qzIWFggODsaxY8dq/czAgQORlpamegx39epV/Pjjjxg+fHid99i4cSMmT55cY3uUTZs2wcHBAb169cLcuXPx4MGDeuubkJCgNjjd09NT47a2VJpO5a+ls5CIiMigNJ7m3759e/Tq1Qvr1q3DoEGDYGVl1aQbFxQUoLKyEs7OzmrHnZ2dcenSpVo/89prr6GgoABPP/00hBB49OgRpk+fjg8//LDW8rt27UJhYSEmTpxY4zqdO3eGm5sbzp07h9mzZyMjIwNJ9Uyrmjt3LmJiYlTvi4uLGZIaoMmUfwCYOFEx842DtYmIyFhovQ5SRESEPuqhkYMHD2LRokVYs2YNAgICcOXKFcycORMLFy6sdQ2mr7/+Gi+++CLc3NzUjk+bNk31+969e8PV1RXPPfccMjMz4e3tXeu9raysmhwKWxrllP/RoxWz1uoKSdnZijKc0UZERMbCYHP1HRwcIJVKkZeXp3Y8Ly+vzrFB8+bNw/jx4zFlyhT07t0bL7/8MhYtWoSEhATI5XK1stevX8f+/fsxZcqUBusSEBAAALhy5UojW0N1CQtTBJ9qGVUNZ7QREZGxMVhAsrS0hL+/P1JSUlTH5HI5UlJSEBgYWOtnHjx4UGP9JalUCkAxSLyqdevWwcnJCX/7298arMuZM2cAAK7c/0IvwsKAb7+tv0zVGW1ERESGpvUjNl2KiYlBREQE+vXrhwEDBiAxMRElJSWqWW0TJkyAu7s7EhISAAChoaFYunQp+vbtq3rENm/ePISGhqqCEqAIWuvWrUNERARatVJvYmZmJjZv3ozhw4ejY8eOOHfuHGbNmoUhQ4agT58+zdf4FiY/X7NynNFGRETGQOuAFB8fj/fee6/GukEPHz7EP//5T8yfP1/ja40ZMwa3b9/G/PnzkZubCz8/PyQnJ6sGbmdlZan1GMXGxkIikSA2NhbZ2dlwdHREaGgoPvnkE7Xr7t+/H1lZWZg8eXKNe1paWmL//v2qMObp6Ynw8HDExsZq88dAWuKMNiIiMiUabTVSlVQqRU5OTo2FHO/cuQMnJyet1kEyZdxqRDuVlYCXV8Mz2jw8OKONiIj0R6dbjVSlXBCyurNnz8Le3l7by1ELockmtsBfM9q4kS0RERmSxgGpQ4cOsLe3h0QiweOPPw57e3vVy9bWFs8//zxeffVVfdaVTBxntBERkanQeAxSYmIihBCYPHkyPv74Y9ja2qrOWVpawsvLq87ZZ0RKYWGArS1QZQH1GrhHGxERGZrGAUm5QGSXLl0waNCgGrPDiDTFGW1ERGTstB6D1L59e1y8eFH1/ocffsCoUaPw4Ycfory8XKeVI/PEGW1ERGTstA5Ib775Jn7//XcAis1ix4wZgzZt2mDbtm344IMPdF5BMj/KPdrqG6wNKPZo42BtIiIyBK0D0u+//w4/Pz8AwLZt2zB06FBs3rwZ69evx44dO3RdPzJDnNFGRETGrlHT/JX7nu3fvx/Dhw8HAHh6eqKgoEC3tSOzxRltRERkzLQOSP369cM//vEPbNiwAYcOHVLtdXbt2jXVCthEmuAebUREZKy0DkiJiYlIT09HVFQUPvroIzz22GMAgO3bt2PgwIE6ryCZN01ntGVn67ceREREVWm91UhdSktLIZVK0bp1a11czuhxqxHdOHgQeOaZhss5OgJr13ILEiIiahpNv78bvZhRWlqaarp/jx498OSTTzb2UtSCKWe0NbRHW0GBYsD29u0MSUREpH9aB6T8/HyMGTMGhw4dgp2dHQCgsLAQzzzzDLZs2QJHR0dd15HMmHJG2+jR9ZcTQjHjLToaGDlS8TkiIiJ90XoM0owZM3D//n389ttvuHv3Lu7evYvz58+juLgY77zzjj7qSGZOOaPNwaH+chywTUREzUXrHqTk5GTs378f3bt3Vx3r0aMHVq9ejWHDhum0ctRyhIUBDx8Cr7/ecFkO2CYiIn3TugdJLpfXOhC7devWqvWRiBrD3V2zcrNmcfFIIiLSL60D0rPPPouZM2fi1q1bqmPZ2dmYNWsWnnvuOZ1WjloWTbcgUQ7YZkgiIiJ90TogrVq1CsXFxfDy8oK3tze8vb3RpUsXFBcXY+XKlfqoI7UQVbcgqQ9X2CYiIn1r1DpIQgjs378fly5dAgB0794dwcHBOq+cMeM6SPqTlAS8+aaip6ghqalAUJDeq0RERGZCr+sgSSQSPP/883j++ecbXUGiunDANhERGZrGj9gOHDiAHj16oLi4uMa5oqIi9OzZE4c5/5p0hAO2iYjIkDQOSImJiZg6dWqt3VG2trZ48803sXTpUp1WjlouDtgmIiJD0jggnT17Fi+88EKd54cNG4a0tDSdVIqIA7aJiMiQNA5IeXl59W5E26pVK9y+fVsnlSICuMI2EREZjsYByd3dHefPn6/z/Llz5+Dq6qqTShEphYUBiYmalc3J0WtViIioBdE4IA0fPhzz5s1DaWlpjXMPHz5EXFwcXnrpJZ1WjgjQfMD25cv6rQcREbUcGq+DlJeXhyeffBJSqRRRUVF44oknAACXLl3C6tWrUVlZifT0dDg7O+u1wsaC6yA1n8pKwMtLMaW/vn+tEonikVxYWLNVjYiITIym399aLRR5/fp1vPXWW9i7dy+UH5NIJAgJCcHq1avRpUuXptfcRDAgNa+kJCA8vP4yEoli5tu1a4pB3kRERNXpJSAp/fnnn7hy5QqEEOjWrRs6dOjQpMqaIgak5hcfD8TFNVxu/36A2wISEVFt9LqSdocOHdC/f/9GV46oMbp106zcq68CX33FR21ERNR4Wm9WS2Qomk6SvHuXi0cSEVHTMCCRydB0dW0lLh5JRESNxYBEJkPT1bWBvxaPPHhQr1UiIiIzxYBEJkW5ura9vWblX32Vj9qIiEh7Bg9Iq1evhpeXF2QyGQICAnDy5Ml6yycmJuKJJ56AtbU1PD09MWvWLLXFKxcsWACJRKL28vHxUbtGaWkpIiMj0bFjR7Rr1w7h4eHIy8vTS/tI98LCgO+/16wsxyMREVFjGDQgbd26FTExMYiLi0N6ejp8fX0REhKC/Pz8Wstv3rwZc+bMQVxcHC5evIivv/4aW7duxYcffqhWrmfPnsjJyVG9jhw5onZ+1qxZ+O9//4tt27bh0KFDuHXrFsI45cmkBAVxPBIREemPQQPS0qVLMXXqVEyaNAk9evTA2rVr0aZNG3zzzTe1lj969CgGDRqE1157DV5eXhg2bBjGjh1bo9epVatWcHFxUb0cqux2WlRUhK+//hpLly7Fs88+C39/f6xbtw5Hjx7F8ePH9dpe0h2ORyIiIn0yWEAqLy9HWloagoOD/6qMhQWCg4Nx7NixWj8zcOBApKWlqQLR1atX8eOPP2L48OFq5S5fvgw3Nzd07doV48aNQ1ZWlupcWloaKioq1O7r4+ODTp061XlfACgrK0NxcbHaiwyL45GIiEhfDBaQCgoKUFlZWWPvNmdnZ+Tm5tb6mddeew3x8fF4+umn0bp1a3h7eyMoKEjtEVtAQADWr1+P5ORkfPHFF7h27RoGDx6Me/fuAQByc3NhaWkJOzs7je8LAAkJCbC1tVW9PD09G9ly0iWORyIiIn0w+CBtbRw8eBCLFi3CmjVrkJ6ejqSkJOzZswcLFy5UlXnxxRfxyiuvoE+fPggJCcGPP/6IwsJCfK/pt2gd5s6di6KiItXrxo0bTW0O6QjHIxERka41aqsRXXBwcIBUKq0xeywvLw8uLi61fmbevHkYP348pkyZAgDo3bs3SkpKMG3aNHz00UewsKiZ9+zs7PD444/jypUrAAAXFxeUl5ejsLBQrRepvvsCgJWVFaysrLRtJjUD5Xik0aMbLlt1PBL3ayMioroYrAfJ0tIS/v7+SElJUR2Ty+VISUlBYGBgrZ958OBBjRAk/d+27XXtuXv//n1kZmbC9X/7VPj7+6N169Zq983IyEBWVlad9yXjx/FIRESkSwbrQQKAmJgYREREoF+/fhgwYAASExNRUlKCSZMmAQAmTJgAd3d3JCQkAABCQ0OxdOlS9O3bFwEBAbhy5QrmzZuH0NBQVVB67733EBoais6dO+PWrVuIi4uDVCrF2LFjAQC2trZ44403EBMTA3t7e9jY2GDGjBkIDAzEU089ZZg/CNKJsDDA1haoMv6+TsrxSNu3c1NbIiKqyaABacyYMbh9+zbmz5+P3Nxc+Pn5ITk5WTVwOysrS63HKDY2FhKJBLGxscjOzoajoyNCQ0PxySefqMrcvHkTY8eOxZ07d+Do6Iinn34ax48fh6Ojo6rMsmXLYGFhgfDwcJSVlSEkJARr1qxpvoaT3ijHI2VnKx6nNSQ6Ghg5UvGYjoiISEki6no2RfUqLi6Gra0tioqKYGNjY+jqUBVJSYreIU3/Ze/fz/FIREQthabf3yY1i41IExyPRERETcWARGaJ6yMREVFTMCCR2eL6SERE1FgMSGS2uF8bERE1FgMSmTWORyIiosZgQCKzx/FIRESkLQYkahG0GY8kBDB9OlBervdqERGRkWJAohZBm/FIAHD7tiJQsSeJiKhlYkCiFkPb8Ui3b/NxGxFRS8WARC2KNuORAD5uIyJqqRiQqMXRdn0kPm4jImp5GJCoxdF2PBLAx21ERC0NAxK1SMrxSA4Omn9GCGDmTK62TUTUEjAgUYsVFgZkZwOOjpp/5uZN4JNP9FcnIiIyDgxI1KJZWgJr12o+HgkA4uL4qI2IyNwxIFGL15jHbZzZRkRk3hiQiKD94zbObCMiMm8MSET/o3zcpinObCMiMl8MSERVhIUBH3+seXkuJElEZJ4YkIiq+egjxeMzTfFxGxGR+WFAIqpGuZCkNjPbbt8GwsOB+Hiuk0REZA4YkIhq0ZiZbYBiCQAvL/YmERGZOgYkojo0ZiFJQLGYJAdvExGZNgYkono0ZiFJgIO3iYhMHQMSUQMa+7iNg7eJiEwXAxKRBhr7uI2Dt4mITBMDEpGGGvu4DeDgbSIiU8OARKQF5eM2d3ftP8vB20REpoMBiUhLYWHA9evarbitxMHbRESmgQGJqBGkUmD+fGDHDg7eJiIyRwxIRE3AwdtEROaJAYmoiTh4m4jI/DAgEelAUwdvszeJiMi4MCAR6UhTBm8D7E0iIjImDEhEOtSUwdsAe5OIiIyFwQPS6tWr4eXlBZlMhoCAAJw8ebLe8omJiXjiiSdgbW0NT09PzJo1C6WlparzCQkJ6N+/P9q3bw8nJyeMGjUKGRkZatcICgqCRCJRe02fPl0v7aOWqbGDt5XYm0REZFgGDUhbt25FTEwM4uLikJ6eDl9fX4SEhCA/P7/W8ps3b8acOXMQFxeHixcv4uuvv8bWrVvx4YcfqsocOnQIkZGROH78OPbt24eKigoMGzYMJSUlateaOnUqcnJyVK8lS5bota3U8jRl8DbwV2/Stm26rRcRETVMIoQQhrp5QEAA+vfvj1WrVgEA5HI5PD09MWPGDMyZM6dG+aioKFy8eBEpKSmqY++++y5OnDiBI0eO1HqP27dvw8nJCYcOHcKQIUMAKHqQ/Pz8kJiYqHFdy8rKUFZWpnpfXFwMT09PFBUVwcbGRuPrUMuTlAS8846iR6kxpFJgyxbFKtxERNQ0xcXFsLW1bfD722A9SOXl5UhLS0NwcPBflbGwQHBwMI4dO1brZwYOHIi0tDTVY7irV6/ixx9/xPDhw+u8T1FREQDA3t5e7fimTZvg4OCAXr16Ye7cuXjw4EG99U1ISICtra3q5enpqVE7iZo6eLuyEnjlFY5LIiJqTgbrQbp16xbc3d1x9OhRBAYGqo5/8MEHOHToEE6cOFHr51asWIH33nsPQgg8evQI06dPxxdffFFrWblcjhEjRqCwsFCth+nLL79E586d4ebmhnPnzmH27NkYMGAAkuoZ8MEeJNKFpvYmOTgAr78OjBwJDB6s6F0iIiLNGX0PUmMcPHgQixYtwpo1a5Ceno6kpCTs2bMHCxcurLV8ZGQkzp8/jy1btqgdnzZtGkJCQtC7d2+MGzcO//73v7Fz505kZmbWeW8rKyvY2NiovYi01dTepIICIDEReOYZDuImItIngwUkBwcHSKVS5OXlqR3Py8uDi4tLrZ+ZN28exo8fjylTpqB37954+eWXsWjRIiQkJEAul6uVjYqKwu7du5GamgoPD4966xIQEAAAuHLlShNaRKSZqksBNGZhSSUuCUBEpD8GC0iWlpbw9/dXG3Atl8uRkpKi9sitqgcPHsDCQr3K0v89Y1A+KRRCICoqCjt37sSBAwfQpUuXButy5swZAICrq2tjmkLUKE3tTVLikgBERLpn0EdsMTEx+Oqrr/Dtt9/i4sWLeOutt1BSUoJJkyYBACZMmIC5c+eqyoeGhuKLL77Ali1bcO3aNezbtw/z5s1DaGioKihFRkZi48aN2Lx5M9q3b4/c3Fzk5ubi4cOHAIDMzEwsXLgQaWlp+OOPP/Cf//wHEyZMwJAhQ9CnT5/m/0OgFk3Zm/T9900bT8TeJCIiHRMGtnLlStGpUydhaWkpBgwYII4fP646N3ToUBEREaF6X1FRIRYsWCC8vb2FTCYTnp6e4u233xZ//vmnqgyAWl/r1q0TQgiRlZUlhgwZIuzt7YWVlZV47LHHxPvvvy+Kioq0qndRUZEAoPXniOqybZsQQNNfDg5CREcLkZoqxKNHhm4VEZFx0fT726DrIJkyTUfBE2mjqbPcqvPwAJYvVzzOIyIiM53FRmTudDUuSYmP3oiIGocBicjIVJ3l1sAETI3FxQEuLsCsWcDBgwxLREQN4SO2RuIjNmoOlZXA4cPADz8AGzcq1kHSBS44SUQtFR+xEZkBqRQICgKWLQNyc3X36K3qgpNOTnwER0RUHQMSkYnQ1QKT1d29q3gE5+zMtZSIiJQYkIhMjK4HcivducMB3URESgxIRCZIHwO5lTigm4iIg7QbjYO0yVjoayC3Egd0E5E50fT7mwGpkRiQyBhVVgKffKLoBdIHhiUiMnWcxUbUAunz0RugPvuNj+GIyJyxB6mR2INExq7qo7dNm4Dbt/V3L/YsEZGp4CM2PWNAIlNSNSx98w1QXKy/ezEsEZExY0DSMwYkMlXKcUqJicCff+r3XgxLRGRsGJD0jAGJTJ2+B3RXZ28PzJihCEr5+YCrK0MTETU/BiQ9Y0Aic5GUBMycCdy82fz3Zg8TETU3BiQ9Y0Aic9KcA7rrwrBERM2BAUnPGJDIXBlTWHrpJcV7PpIjIl1hQNIzBiRqCYwhLFXF4ERETcWApGcMSNTSGFtYqoqP54hIUwxIesaARC2ZMYclzpYjovowIOkZAxKRgjGHJSU+miMiJQYkPWNAIqqpOVfs1oXagpOT01+/Z4giMj8MSHrGgERUP+VClMuXA3fvGro2jcfeJyLzwoCkZwxIRJpR9irl5PzVO7N7t/E+jtNU9bFO7HkiMg0MSHrGgETUNKYwdqkp+PiOyDgxIOkZAxKR7ph7WKpLfSEqN1fx5+DoCLi7M0wR6QoDkp4xIBHph7k+kmuqhnqk6vo9e6qI1DEg6RkDElHzqis4mcJsOUPTtKfKxeWv8wxWZK4YkPSMAYnIOJjLbDlj1Nheq9p+z0eGZCwYkPSMAYnIuPDRnGnRZfjSJJSxd4yUGJD0jAGJyDQwOFFt9NU7VjWINVfg4/gz7TAg6RkDEpFpqy04Vf2CYYgic9CYIGhMgU8fIY8BSc8YkIjMX/UQdfgwsHIlxzoRNScPD8UYw7Aw3VyPAUnPGJCIWib2PBE1L4lE8ev27boJSZp+f1s0/VZNs3r1anh5eUEmkyEgIAAnT56st3xiYiKeeOIJWFtbw9PTE7NmzUJpaalW1ywtLUVkZCQ6duyIdu3aITw8HHl5eTpvGxGZH6kUCAoCxo4FnntO8ar6+2XLFOEpNRXYvBnYv1/xqvr76GjFYwUiapiyGyc6WvE/KM3FoD1IW7duxYQJE7B27VoEBAQgMTER27ZtQ0ZGBpyU/ztWxebNmzF58mR88803GDhwIH7//XdMnDgRf//737F06VKNr/nWW29hz549WL9+PWxtbREVFQULCwv88ssvGtedPUhE1BQN9UQpx2f88YciXLFHikjxPx5BQU27hkk8YgsICED//v2xatUqAIBcLoenpydmzJiBOXPm1CgfFRWFixcvIiUlRXXs3XffxYkTJ3DkyBGNrllUVARHR0ds3rwZo0ePBgBcunQJ3bt3x7Fjx/DUU09pVHcGJCJqLg2Fqbp+z8d9ZG42b1b02DaFpt/frZp2m8YrLy9HWloa5s6dqzpmYWGB4OBgHDt2rNbPDBw4EBs3bsTJkycxYMAAXL16FT/++CPGjx+v8TXT0tJQUVGB4OBgVRkfHx906tSp3oBUVlaGsrIy1ftiLt1LRM1E+VhPW889B3z2mWY9VVVnEjFYkbFydW2+exksIBUUFKCyshLOzs5qx52dnXHp0qVaP/Paa6+hoKAATz/9NIQQePToEaZPn44PP/xQ42vm5ubC0tISdnZ2Ncrk5ubWWd+EhAR8/PHH2jaTiMigGhOuNAlWjZ3SzUeG1BgSiWI22+DBzXdPgwWkxjh48CAWLVqENWvWICAgAFeuXMHMmTOxcOFCzJs3T6/3njt3LmJiYlTvi4uL4enpqdd7EhEZSmN7rTTx+ee6DV/arLPD3jHTo5zFlpjYvIteGiwgOTg4QCqV1pg9lpeXBxflv+Rq5s2bh/Hjx2PKlCkAgN69e6OkpATTpk3DRx99pNE1XVxcUF5ejsLCQrVepPruCwBWVlawsrJqTFOJiKgKfYavhuizd8wYFlY0x/FnHh6KcKSrdZA0ZbCAZGlpCX9/f6SkpGDUqFEAFAOqU1JSEBUVVetnHjx4AAsL9ZUJpP+Lk0IIja7p7++P1q1bIyUlBeHh4QCAjIwMZGVlITAwUA8tJSIiY2LIgNZcmhIEjSnwGXK7FIM+YouJiUFERAT69euHAQMGIDExESUlJZg0aRIAYMKECXB3d0dCQgIAIDQ0FEuXLkXfvn1Vj9jmzZuH0NBQVVBq6Jq2trZ44403EBMTA3t7e9jY2GDGjBkIDAzUeAYbERGRsWsJQVCfDBqQxowZg9u3b2P+/PnIzc2Fn58fkpOTVYOss7Ky1HqMYmNjIZFIEBsbi+zsbDg6OiI0NBSffPKJxtcEgGXLlsHCwgLh4eEoKytDSEgI1qxZ03wNJyIiIqPGrUYaiesgERERmR6T2WqEiIiIyNgwIBERERFVw4BEREREVA0DEhEREVE1DEhERERE1TAgEREREVXDgERERERUjUltVmtMlMtHFRcXG7gmREREpCnl93ZDy0AyIDXSvXv3AACenp4GrgkRERFp6969e7C1ta3zPFfSbiS5XI5bt26hffv2kEgkTbpWcXExPD09cePGDbNelZvtNC9sp/loCW0E2E5z09h2CiFw7949uLm5qW1nVh17kBrJwsICHh4eOr2mjY2NWf9jVmI7zQvbaT5aQhsBttPcNKad9fUcKXGQNhEREVE1DEhERERE1TAgGQErKyvExcXBysrK0FXRK7bTvLCd5qMltBFgO82NvtvJQdpERERE1bAHiYiIiKgaBiQiIiKiahiQiIiIiKphQCIiIiKqhgHJCKxevRpeXl6QyWQICAjAyZMnDV2lRktISED//v3Rvn17ODk5YdSoUcjIyFArU1paisjISHTs2BHt2rVDeHg48vLyDFRj3Vi8eDEkEgmio6NVx8ylndnZ2Xj99dfRsWNHWFtbo3fv3jh16pTqvBAC8+fPh6urK6ytrREcHIzLly8bsMbaq6ysxLx589ClSxdYW1vD29sbCxcuVNuryRTb+fPPPyM0NBRubm6QSCTYtWuX2nlN2nT37l2MGzcONjY2sLOzwxtvvIH79+83YysaVl87KyoqMHv2bPTu3Rtt27aFm5sbJkyYgFu3bqldw9jb2dDfZVXTp0+HRCJBYmKi2nFjbyOgWTsvXryIESNGwNbWFm3btkX//v2RlZWlOq+rn70MSAa2detWxMTEIC4uDunp6fD19UVISAjy8/MNXbVGOXToECIjI3H8+HHs27cPFRUVGDZsGEpKSlRlZs2ahf/+97/Ytm0bDh06hFu3biEsLMyAtW6aX3/9Ff/617/Qp08ftePm0M4///wTgwYNQuvWrfHTTz/hwoUL+Pzzz9GhQwdVmSVLlmDFihVYu3YtTpw4gbZt2yIkJASlpaUGrLl2Pv30U3zxxRdYtWoVLl68iE8//RRLlizBypUrVWVMsZ0lJSXw9fXF6tWraz2vSZvGjRuH3377Dfv27cPu3bvx888/Y9q0ac3VBI3U184HDx4gPT0d8+bNQ3p6OpKSkpCRkYERI0aolTP2djb0d6m0c+dOHD9+HG5ubjXOGXsbgYbbmZmZiaeffho+Pj44ePAgzp07h3nz5kEmk6nK6OxnryCDGjBggIiMjFS9r6ysFG5ubiIhIcGAtdKd/Px8AUAcOnRICCFEYWGhaN26tdi2bZuqzMWLFwUAcezYMUNVs9Hu3bsnunXrJvbt2yeGDh0qZs6cKYQwn3bOnj1bPP3003Wel8vlwsXFRfzzn/9UHSssLBRWVlbiu+++a44q6sTf/vY3MXnyZLVjYWFhYty4cUII82gnALFz507Ve03adOHCBQFA/Prrr6oyP/30k5BIJCI7O7vZ6q6N6u2szcmTJwUAcf36dSGE6bWzrjbevHlTuLu7i/Pnz4vOnTuLZcuWqc6ZWhuFqL2dY8aMEa+//nqdn9Hlz172IBlQeXk50tLSEBwcrDpmYWGB4OBgHDt2zIA1052ioiIAgL29PQAgLS0NFRUVam328fFBp06dTLLNkZGR+Nvf/qbWHsB82vmf//wH/fr1wyuvvAInJyf07dsXX331ler8tWvXkJubq9ZOW1tbBAQEmFQ7Bw4ciJSUFPz+++8AgLNnz+LIkSN48cUXAZhPO6vSpE3Hjh2DnZ0d+vXrpyoTHBwMCwsLnDhxotnrrCtFRUWQSCSws7MDYB7tlMvlGD9+PN5//3307NmzxnlzaeOePXvw+OOPIyQkBE5OTggICFB7DKfLn70MSAZUUFCAyspKODs7qx13dnZGbm6ugWqlO3K5HNHR0Rg0aBB69eoFAMjNzYWlpaXqB5OSKbZ5y5YtSE9PR0JCQo1z5tLOq1ev4osvvkC3bt2wd+9evPXWW3jnnXfw7bffAoCqLab+b3jOnDn4+9//Dh8fH7Ru3Rp9+/ZFdHQ0xo0bB8B82lmVJm3Kzc2Fk5OT2vlWrVrB3t7eZNtdWlqK2bNnY+zYsaoNTs2hnZ9++ilatWqFd955p9bz5tDG/Px83L9/H4sXL8YLL7yA//f//h9efvllhIWF4dChQwB0+7O3la4qTlRdZGQkzp8/jyNHjhi6Kjp348YNzJw5E/v27VN79m1u5HI5+vXrh0WLFgEA+vbti/Pnz2Pt2rWIiIgwcO105/vvv8emTZuwefNm9OzZE2fOnEF0dDTc3NzMqp0tXUVFBV599VUIIfDFF18Yujo6k5aWhuXLlyM9PR0SicTQ1dEbuVwOABg5ciRmzZoFAPDz88PRo0exdu1aDB06VKf3Yw+SATk4OEAqldYYXZ+XlwcXFxcD1Uo3oqKisHv3bqSmpsLDw0N13MXFBeXl5SgsLFQrb2ptTktLQ35+Pp588km0atUKrVq1wqFDh7BixQq0atUKzs7OZtFOV1dX9OjRQ+1Y9+7dVTNGlG0x9X/D77//vqoXqXfv3hg/fjxmzZql6h00l3ZWpUmbXFxcakwYefToEe7evWty7VaGo+vXr2Pfvn2q3iPA9Nt5+PBh5Ofno1OnTqqfR9evX8e7774LLy8vAKbfRkDxndmqVasGfybp6mcvA5IBWVpawt/fHykpKapjcrkcKSkpCAwMNGDNGk8IgaioKOzcuRMHDhxAly5d1M77+/ujdevWam3OyMhAVlaWSbX5ueeew//93//hzJkzqle/fv0wbtw41e/NoZ2DBg2qsUzD77//js6dOwMAunTpAhcXF7V2FhcX48SJEybVzgcPHsDCQv3HoVQqVf0fq7m0sypN2hQYGIjCwkKkpaWpyhw4cAByuRwBAQHNXufGUoajy5cvY//+/ejYsaPaeVNv5/jx43Hu3Dm1n0dubm54//33sXfvXgCm30ZA8Z3Zv3//en8m6fQ7Rqsh3aRzW7ZsEVZWVmL9+vXiwoULYtq0acLOzk7k5uYaumqN8tZbbwlbW1tx8OBBkZOTo3o9ePBAVWb69OmiU6dO4sCBA+LUqVMiMDBQBAYGGrDWulF1FpsQ5tHOkydPilatWolPPvlEXL58WWzatEm0adNGbNy4UVVm8eLFws7OTvzwww/i3LlzYuTIkaJLly7i4cOHBqy5diIiIoS7u7vYvXu3uHbtmkhKShIODg7igw8+UJUxxXbeu3dPnD59Wpw+fVoAEEuXLhWnT59Wzd7SpE0vvPCC6Nu3rzhx4oQ4cuSI6Natmxg7dqyhmlSr+tpZXl4uRowYITw8PMSZM2fUfi6VlZWprmHs7Wzo77K66rPYhDD+NgrRcDuTkpJE69atxZdffikuX74sVq5cKaRSqTh8+LDqGrr62cuAZARWrlwpOnXqJCwtLcWAAQPE8ePHDV2lRgNQ62vdunWqMg8fPhRvv/226NChg2jTpo14+eWXRU5OjuEqrSPVA5K5tPO///2v6NWrl7CyshI+Pj7iyy+/VDsvl8vFvHnzhLOzs7CyshLPPfecyMjIMFBtG6e4uFjMnDlTdOrUSchkMtG1a1fx0UcfqX2BmmI7U1NTa/3vMSIiQgihWZvu3Lkjxo4dK9q1aydsbGzEpEmTxL179wzQmrrV185r167V+XMpNTVVdQ1jb2dDf5fV1RaQjL2NQmjWzq+//lo89thjQiaTCV9fX7Fr1y61a+jqZ69EiCpLxRIRERERxyARERERVceARERERFQNAxIRERFRNQxIRERERNUwIBERERFVw4BEREREVA0DEhEREVE1DEhERERE1TAgEZHB/PHHH5BIJDhz5oyhq6Jy6dIlPPXUU5DJZPDz86u1TFBQEKKjo5u1XpqQSCTYtWuXoatBZBYYkIhasIkTJ0IikWDx4sVqx3ft2gWJRGKgWhlWXFwc2rZti4yMDLUNL6tKSkrCwoULVe+9vLyQmJjYTDUEFixYUGt4y8nJwYsvvths9SAyZwxIRC2cTCbDp59+ij///NPQVdGZ8vLyRn82MzMTTz/9NDp37lxj13cle3t7tG/fvtH3qEtT6g0ALi4usLKy0lFtiFo2BiSiFi44OBguLi5ISEios0xtPRaJiYnw8vJSvZ84cSJGjRqFRYsWwdnZGXZ2doiPj8ejR4/w/vvvw97eHh4eHli3bl2N61+6dAkDBw6ETCZDr169cOjQIbXz58+fx4svvoh27drB2dkZ48ePR0FBgep8UFAQoqKiEB0dDQcHB4SEhNTaDrlcjvj4eHh4eMDKygp+fn5ITk5WnZdIJEhLS0N8fDwkEgkWLFhQ63WqPmILCgrC9evXMWvWLEgkErWetyNHjmDw4MGwtraGp6cn3nnnHZSUlKjOe3l5YeHChZgwYQJsbGwwbdo0AMDs2bPx+OOPo02bNujatSvmzZuHiooKAMD69evx8ccf4+zZs6r7rV+/XlX/qo/Y/u///g/PPvssrK2t0bFjR0ybNg3379+v8Xf22WefwdXVFR07dkRkZKTqXgCwZs0adOvWDTKZDM7Ozhg9enStfyZE5oYBiaiFk0qlWLRoEVauXImbN2826VoHDhzArVu38PPPP2Pp0qWIi4vDSy+9hA4dOuDEiROYPn063nzzzRr3ef/99/Huu+/i9OnTCAwMRGhoKO7cuQMAKCwsxLPPPou+ffvi1KlTSE5ORl5eHl599VW1a3z77bewtLTEL7/8grVr19Zav+XLl+Pzzz/HZ599hnPnziEkJAQjRozA5cuXASgeUfXs2RPvvvsucnJy8N577zXY5qSkJHh4eCA+Ph45OTnIyckBoOiJeuGFFxAeHo5z585h69atOHLkCKKiotQ+/9lnn8HX1xenT5/GvHnzAADt27fH+vXrceHCBSxfvhxfffUVli1bBgAYM2YM3n33XfTs2VN1vzFjxtSoV0lJCUJCQtChQwf8+uuv2LZtG/bv31/j/qmpqcjMzERqaiq+/fZbrF+/XhW4Tp06hXfeeQfx8fHIyMhAcnIyhgwZ0uCfCZFZEETUYkVERIiRI0cKIYR46qmnxOTJk4UQQuzcuVNU/fEQFxcnfH191T67bNky0blzZ7Vrde7cWVRWVqqOPfHEE2Lw4MGq948ePRJt27YV3333nRBCiGvXrgkAYvHixaoyFRUVwsPDQ3z66adCCCEWLlwohg0bpnbvGzduCAAiIyNDCCHE0KFDRd++fRtsr5ubm/jkk0/UjvXv31+8/fbbqve+vr4iLi6u3usMHTpUzJw5U/W+c+fOYtmyZWpl3njjDTFt2jS1Y4cPHxYWFhbi4cOHqs+NGjWqwXr/85//FP7+/qr3tf19CCEEALFz504hhBBffvml6NChg7h//77q/J49e4SFhYXIzc0VQvz1d/bo0SNVmVdeeUWMGTNGCCHEjh07hI2NjSguLm6wjkTmhj1IRAQA+PTTT/Htt9/i4sWLjb5Gz549YWHx148VZ2dn9O7dW/VeKpWiY8eOyM/PV/tcYGCg6vetWrVCv379VPU4e/YsUlNT0a5dO9XLx8cHgKKXRsnf37/euhUXF+PWrVsYNGiQ2vFBgwY1qc11OXv2LNavX69W75CQEMjlcly7dk1Vrl+/fjU+u3XrVgwaNAguLi5o164dYmNjkZWVpdX9L168CF9fX7Rt21Z1bNCgQZDL5cjIyFAd69mzJ6RSqeq9q6ur6u/n+eefR+fOndG1a1eMHz8emzZtwoMHD7SqB5GpYkAiIgDAkCFDEBISgrlz59Y4Z2FhASGE2rGq41SUWrdurfZeIpHUekwul2tcr/v37yM0NBRnzpxRe12+fFntcU/VIGAM7t+/jzfffFOtzmfPnsXly5fh7e2tKle93seOHcO4ceMwfPhw7N69G6dPn8ZHH33U5AHcdanv76d9+/ZIT0/Hd999B1dXV8yfPx++vr4oLCzUS12IjEkrQ1eAiIzH4sWL4efnhyeeeELtuKOjI3JzcyGEUA1C1uXaRcePH1eFnUePHiEtLU01VubJJ5/Ejh074OXlhVatGv8jy8bGBm5ubvjll18wdOhQ1fFffvkFAwYMaFL9LS0tUVlZqXbsySefxIULF/DYY49pda2jR4+ic+fO+Oijj1THrl+/3uD9quvevTvWr1+PkpISVQj75ZdfYGFhUePvtz6tWrVCcHAwgoODERcXBzs7Oxw4cABhYWFatIrI9LAHiYhUevfujXHjxmHFihVqx4OCgnD79m0sWbIEmZmZWL16NX766Sed3Xf16tXYuXMnLl26hMjISPz555+YPHkyACAyMhJ3797F2LFj8euvvyIzMxN79+7FpEmTGgwJ1b3//vv49NNPsXXrVmRkZGDOnDk4c+YMZs6c2aT6e3l54eeff0Z2drZqdt3s2bNx9OhRREVFqXq8fvjhhxqDpKvr1q0bsrKysGXLFmRmZmLFihXYuXNnjftdu3YNZ86cQUFBAcrKympcZ9y4cZDJZIiIiMD58+eRmpqKGTNmYPz48XB2dtaoXbt378aKFStw5swZXL9+Hf/+978hl8u1ClhEpooBiYjUxMfH13gE1r17d6xZswarV6+Gr68vTp48qdEML00tXrwYixcvhq+vL44cOYL//Oc/cHBwAABVr09lZSWGDRuG3r17Izo6GnZ2dmrjnTTxzjvvICYmBu+++y569+6N5ORk/Oc//0G3bt2aVP/4+Hj88ccf8Pb2hqOjIwCgT58+OHToEH7//XcMHjwYffv2xfz58+Hm5lbvtUaMGIFZs2YhKioKfn5+OHr0qGp2m1J4eDheeOEFPPPMM3B0dMR3331X4zpt2rTB3r17cffuXfTv3x+jR4/Gc889h1WrVmncLjs7OyQlJeHZZ59F9+7dsXbtWnz33Xfo2bOnxtcgMlUSUX1gAREREVELxx4kIiIiomoYkIiIiIiqYUAiIiIiqoYBiYiIiKgaBiQiIiKiahiQiIiIiKphQCIiIiKqhgGJiIiIqBoGJCIiIqJqGJCIiIiIqmFAIiIiIqrm/wN12eyy1mdNMgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "iterations = np.array([x+1 for x in range(costs.size)])\n",
        "plt.scatter(iterations, costs, color = \"blue\")\n",
        "plt.ylabel(\"Cost function (MSE)\")\n",
        "plt.xlabel(\"Number of iterations\")\n",
        "plt.xticks()\n",
        "plt.yticks()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb1CVeLxhEyF"
      },
      "source": [
        "> What are the conclusions? (1-2 paragraphs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nas primeiras iterações, observa-se que a queda no MSE entre uma iteração e a seguinte é mais significativa. Conforme se aumenta o número de iterações, as variações do MSE se tornam mais sutis, até o ponto em que há praticamente uma estabilização de seus valores. A estabilização do MSE indica que a Regressão Linear não obterá resultados muito melhores para os pesos, mesmo que continue executando por um maior período de tempo e, portanto, a solução obtida será uma das mais próximas possível da solução ótima, sem um grande aumento do custo computacional.\n",
        "\n",
        "De maneira geral, o comportamento da função custo (MSE) em função do número de iterações do algoritmo apresenta uma forma parecida com a de uma exponencial fracionária (como $e^{1/x}$). Isso parece indicar um funcionamento adequado do modelo, o qual tende a convergir para um menor valor de MSE conforme avançam as iterações."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGvnz52Aa-7B"
      },
      "source": [
        "4. (0.75 points) Use different learning rates when optimizing the model. You can use the model that you implemented or the model from scikit-learn.\n",
        "\n",
        "> If you prefer to use the SGDRegressor from scikit-learn, use the parameter ```learning_rate='constant'``` and change the ```eta0```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "dBaZ-WKPHCp1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using scikit-learn SGDRegressor model\n",
            "Learning rate: 0.01\t\tMSE = 1.6813\n",
            "Learning rate: 0.02\t\tMSE = 1.6846\n",
            "Learning rate: 0.05\t\tMSE = 1.4942\n",
            "Learning rate: 0.1\t\tMSE = 1.5745\n",
            "Learning rate: 0.2\t\tMSE = 1.8417\n",
            "Learning rate: 0.5\t\tMSE = 6.042785257253157e+24\n",
            "Learning rate: 1.0\t\tMSE = 1.589562861859573e+25\n",
            "Learning rate: 2.0\t\tMSE = 3.6879694464160613e+25\n",
            "Learning rate: 5.0\t\tMSE = 6.624569196352351e+26\n",
            "Learning rate: 10.0\t\tMSE = 3.3363838150051264e+27\n"
          ]
        }
      ],
      "source": [
        "# Different learning rates. Using scikit-learn libraries.\n",
        "learning_rates = np.array([0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10])\n",
        "errors = np.array([])\n",
        "\n",
        "for rate in learning_rates:\n",
        "    scikit_model = SGDRegressor(learning_rate='constant', eta0=rate, random_state=42)\n",
        "    scikit_model.fit(X_train, y_train)\n",
        "    y_pred = scikit_model.predict(X_valid)\n",
        "    errors = np.append(errors, MSE(y_valid, y_pred))\n",
        "\n",
        "print(\"Using scikit-learn SGDRegressor model\")\n",
        "for i in range(len(learning_rates)):\n",
        "    print(f\"Learning rate: {learning_rates[i]}\\t\\tMSE = {round(errors[i], 4)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using self implemented Linear Regression\n",
            "Learning rate: 0.01\t\tMSE = 1.6561\n",
            "Learning rate: 0.02\t\tMSE = 1.6583\n",
            "Learning rate: 0.05\t\tMSE = 1.6606\n",
            "Learning rate: 0.1\t\tMSE = 1.6619\n",
            "Learning rate: 0.2\t\tMSE = 1.6632\n",
            "Learning rate: 0.5\t\tMSE = 1.6651\n",
            "Learning rate: 1.0\t\tMSE = 1.6658\n",
            "Learning rate: 2.0\t\tMSE = 2.4494\n",
            "Learning rate: 5.0\t\tMSE = 7.4235\n",
            "Learning rate: 10.0\t\tMSE = 25.6144\n"
          ]
        }
      ],
      "source": [
        "# Different learning rates. Using model implemented by us.\n",
        "errors = np.array([])\n",
        "\n",
        "for rate in learning_rates:\n",
        "    model = LinearRegression(learning_rate=rate, max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_valid)\n",
        "    errors = np.append(errors, MSE(y_valid, y_pred))\n",
        "\n",
        "print(\"Using self implemented Linear Regression\")\n",
        "for i in range(len(learning_rates)):\n",
        "    print(f\"Learning rate: {learning_rates[i]}\\t\\tMSE = {round(errors[i], 4)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwZIA0Tucpe0"
      },
      "source": [
        "> What are the conclusions? (1-2 paragraphs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para taxas de aprendizado mais baixas, entre 0.01 e 0.5, há uma certa consistência nos erros obtidos, os quais se mantêm próximos a 0.08. Esses resultados indicam um bom funcionamento dos modelos para essas menores taxas de aprendizados. Porém, conforme se aumenta a taxa de aprendizado para valores acima de 0.5, observa-se um aumento no MSE resultante, especialmente utilizando o ```SGDRegressor``` do scikit-learn, enquanto para o modelo implementado manualmente, um aumento mais significativo no MSE é observado para taxas de aprendizado a partir de 5.\n",
        "\n",
        "Assim, com essas maiores taxas, é notável que os modelos deixam de funcionar de maneira desejável, passando a apresentar erros consideravelmente grandes. Esse fato muito possivelmente é resultado de overshooting. De maneira geral, esse procedimento de validação permite com que haja um ajuste dos hiperparâmetros, mais especificamente da taxa de aprendizado, para que o treinamento do modelo apresente um melhor desempenho."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSeBs0gycPpW"
      },
      "source": [
        "5. (0.5 points) Sometimes, we need some more complex function to make good prediction. Evaluate a [Polynomial Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "7qS_AG9fcM0O"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best results with degree 2 (MSE = 1.4537589763547782)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "degrees = np.array([x+1 for x in range(15)])\n",
        "\n",
        "best_deg = degrees[0]\n",
        "best_mse = None\n",
        "\n",
        "for deg in degrees:\n",
        "    pol_features = PolynomialFeatures(degree=deg)\n",
        "    X_train_pol = pol_features.fit_transform(X_train)\n",
        "\n",
        "    model = SGDRegressor(random_state=42)\n",
        "    model.fit(X_train_pol, y_train)\n",
        "\n",
        "    X_valid_pol = pol_features.fit_transform(X_valid)\n",
        "\n",
        "    y_pred_pol = model.predict(X_valid_pol)\n",
        "    \n",
        "    current_mse = MSE(y_valid, y_pred_pol)\n",
        "\n",
        "    if (best_mse is None or current_mse < best_mse):\n",
        "        best_mse = current_mse\n",
        "        best_deg = deg\n",
        "\n",
        "print(f\"Best results with degree {best_deg} (MSE = {best_mse})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSJSICf7cqaH"
      },
      "source": [
        "> What are the conclusions? (1-2 paragraphs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Foram realizadas regressões lineares ajustando os dados a polinômios de graus 1 a 15, buscando o que fornecesse o menor erro (MSE) no conjunto de validação. Esse procedimento é realizado com a intenção de encontrar o modelo que melhor se ajusta aos dados reais e não somente aos dados do conjunto de treinamento. Ao utilizar o conjunto de validação para selecionar o grau do polinômio que melhor se adequa aos dados, busca-se evitar a ocorrência de overfitting, ou seja, a escolha de um polinômio que se ajusta muito bem ao conjunto de treinamento, mas não ao conjunto total de dados.\n",
        "\n",
        "Com isso, o polinômio de grau 4 foi o que apresentou o menor MSE dentre os polinômios testados e, portanto, corresponde ao melhor resultado obtido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCpz412ac6X7"
      },
      "source": [
        "6. (0.5 points) Pick **your best model**, based on your validation set, and predict the target values for the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "qRUE-ElIc5pl"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# The plot shows the true label (red) and the predict label (blue)\n",
        "# for each data entry in the test set\n",
        "\n",
        "pol_features = PolynomialFeatures(degree=best_deg)\n",
        "X_train_pol = pol_features.fit_transform(X_train)\n",
        "\n",
        "model = SGDRegressor(random_state=42)\n",
        "model.fit(X_train_pol, y_train)\n",
        "\n",
        "X_test_pol = pol_features.fit_transform(X_test)\n",
        "\n",
        "y_pred = model.predict(X_test_pol)\n",
        "\n",
        "num = np.array([x+1 for x in range(y_pred.size)])\n",
        "plt.scatter(num, y_pred, color = \"blue\", label=\"Predicted value\")\n",
        "plt.scatter(num, y_test, color = \"red\", label=\"True Label\")\n",
        "plt.ylabel(\"Target Value\")\n",
        "plt.xlabel(\"Data Entry\")\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1wu27uZdigS"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbmfqspmdosV"
      },
      "source": [
        "This part of the assigment aims to predict the patients survival based on their medical records. \n",
        "\n",
        "*   Do we need to split the data into train, valid and test? How?\n",
        "*   Do we need to normalize the data? How? The normalization is equal to train, valid and test split?\n",
        "* **Target value: DEATH EVENT**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQjs5xhmgDV-"
      },
      "source": [
        "1. (0.5 points) Verify if there is any feature that has low correlation with the target variables. You can use the function [mutual_info_classification](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html) to check the importance of each feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "AXwPiduYdmla"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting data into train and test sets\n",
        "X_train, X_test = train_test_split(df, test_size = 0.4, random_state = my_seed)\n",
        "X_test, X_valid = train_test_split(X_test, test_size = 0.5, random_state = my_seed)\n",
        "\n",
        "y_train= X_train[\"DEATH_EVENT\"]\n",
        "X_train = X_train[X_train.columns.drop([\"DEATH_EVENT\"])]\n",
        "\n",
        "y_test= X_test[\"DEATH_EVENT\"]\n",
        "X_test = X_test[X_test.columns.drop([\"DEATH_EVENT\"])]\n",
        "\n",
        "y_valid= X_valid[\"DEATH_EVENT\"]\n",
        "X_valid = X_valid[X_valid.columns.drop([\"DEATH_EVENT\"])]\n",
        "\n",
        "# Feature selection.\n",
        "correlation = mutual_info_classif(X_train, y_train, random_state= my_seed)\n",
        "idx = np.array([]).astype(int)\n",
        "for i in range(len(correlation)):\n",
        "    if correlation[i] <= 0.02:\n",
        "        idx = np.append(idx, i)\n",
        "\n",
        "# Columns with low correlation are dropped\n",
        "X_train = X_train.drop(X_train.columns[idx], axis = 1)\n",
        "X_test = X_test.drop(X_test.columns[idx], axis = 1)\n",
        "X_valid = X_valid.drop(X_valid.columns[idx], axis = 1)\n",
        "\n",
        "# Normalizing the dataset\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_valid = scaler.transform(X_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLLg2Np1jVTh"
      },
      "source": [
        "> What are the conclusions? (1-2 paragraphs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nessa etapa, houve a divisão do conjunto de dados apenas entre treinamento e teste. Já em relação à normalização dos dados, foi utilizada a classe StandardScaler, a qual foi aplicada individualmente em cada conjunto, para que o teste não fosse contaminado pelo treinamento.\n",
        "\n",
        "O procedimento de feature selection foi realizado com o auxílio da função ```mutual_info_classif``` do scikit learn. A partir dessa, obteve-se uma estimativa da correlação entre o valor alvo e cada uma das features. Assim, aquelas que apresentaram uma correlação menor que 0.02, segundo o resultado obtido pelo ```mutual_info_classif```, foram desconsideradas no treinamento do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gvvAB4WgWbK"
      },
      "source": [
        "2. (2 points) Perform Multinomial Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "C8DCclQ1ghBl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "On training set:\n",
            "Cross entropy: 6.74\n",
            "Accuracy: 0.81\n",
            "\n",
            "On testing set:\n",
            "Cross entropy: 13.86\n",
            "Accuracy: 0.62\n"
          ]
        }
      ],
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.metrics import log_loss, accuracy_score\n",
        "import seaborn as sn    \n",
        "\n",
        "# Validation for selecting hyperparameters\n",
        "\n",
        "C_candidates = [0.1, 0.5, 1, 2, 5, 10, 20]\n",
        "\n",
        "best_C = None\n",
        "best_accuracy = 0\n",
        "\n",
        "for c in C_candidates:\n",
        "    model = linear_model.LogisticRegression(C=c, random_state=my_seed, multi_class='multinomial', solver='saga')\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred_valid = model.predict(X_valid)\n",
        "    if (accuracy_score(y_valid, y_pred_valid) >= best_accuracy):\n",
        "        best_C = c\n",
        "        best_accuracy = accuracy_score(y_valid, y_pred_valid)\n",
        "\n",
        "# Train the model using the training set and the hyperparameters determined during validation\n",
        "model = linear_model.LogisticRegression(C=best_C, random_state=my_seed, multi_class='multinomial', solver='saga')\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print('\\nOn training set:')\n",
        "y_pred_train = model.predict(X_train)\n",
        "print(\"Cross entropy: %.2f\" % log_loss(y_train, y_pred_train))\n",
        "print(\"Accuracy: %.2f\" % accuracy_score(y_train, y_pred_train))\n",
        "print('\\nOn testing set:')\n",
        "y_pred_test = model.predict(X_test)\n",
        "print(\"Cross entropy: %.2f\" % log_loss(y_test, y_pred_test))\n",
        "print(\"Accuracy: %.2f\" % accuracy_score(y_test, y_pred_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xdkr3A1jTzC"
      },
      "source": [
        "> What are the conclusions? (1-2 paragraphs)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para realizar a Regressão Logística Multinomial, o modelo foi treinado passando os parâmetros ```multi_class='multinomial'``` e ```solver='saga'``` para o LogisticRegression do sklearn. Além disso, foi realizado o procedimento de validação para determinar a melhor constante de regularização ```C``` a ser utilizada no modelo treinado.\n",
        "\n",
        "Os resultados obtidos apresentaram uma acurácia de 81% para o conjunto de treinamento e 62% para o conjunto de teste. Assim, os valores de acurácia resultante indicam um desempenho razoável do modelo treinado, sendo que há a previsão correta para quase mais da metade dos casos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ_34cx1hd6J"
      },
      "source": [
        "3. (1.5 points) Another factor that can alter the model result it's if the dataset is balanced:\n",
        "\n",
        "*   The dataset is balanced ?\n",
        "*   In this case, which technique is better: *oversampling* or *undersampling*?\n",
        "\n",
        "Obs: You can use [RandomOverSampling](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html) and [RandomUnderSampling](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html#imblearn.under_sampling.RandomUnderSampler). But you can try others techniques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "CiFVP2Zrgyxc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "On training set:\n",
            "Cross entropy: 6.74\n",
            "Accuracy: 0.81\n",
            "\n",
            "On testing set:\n",
            "Cross entropy: 13.17\n",
            "Accuracy: 0.63\n"
          ]
        }
      ],
      "source": [
        "# Oversampling\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler(random_state=my_seed)\n",
        "X_train_over, y_train_over = ros.fit_resample(X_train, y_train)\n",
        "model = linear_model.LogisticRegression(C = best_C, random_state=my_seed, multi_class='multinomial', solver='saga')\n",
        "# Train the model using the training set\n",
        "model.fit(X_train_over, y_train_over)\n",
        "\n",
        "print('\\nOn training set:')\n",
        "y_pred_over_train = model.predict(X_train_over)\n",
        "print(\"Cross entropy: %.2f\" % log_loss(y_train_over, y_pred_over_train))\n",
        "print(\"Accuracy: %.2f\" % accuracy_score(y_train_over, y_pred_over_train))\n",
        "print('\\nOn testing set:')\n",
        "y_pred_over_test = model.predict(X_test)\n",
        "print(\"Cross entropy: %.2f\" % log_loss(y_test, y_pred_over_test))\n",
        "print(\"Accuracy: %.2f\" % accuracy_score(y_test, y_pred_over_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "TuCBPbc5jHbl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "On training set:\n",
            "Cross entropy: 6.76\n",
            "Accuracy: 0.81\n",
            "\n",
            "On testing set:\n",
            "Cross entropy: 13.86\n",
            "Accuracy: 0.62\n"
          ]
        }
      ],
      "source": [
        "# Undersampling\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rus = RandomUnderSampler(random_state=my_seed)\n",
        "X_train_under, y_train_under = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "model = linear_model.LogisticRegression(C = best_C, random_state=my_seed, multi_class='multinomial', solver='saga')\n",
        "\n",
        "# Train the model using the training set\n",
        "model.fit(X_train_under, y_train_under)\n",
        "\n",
        "print('\\nOn training set:')\n",
        "y_pred_under_train = model.predict(X_train_under)\n",
        "print(\"Cross entropy: %.2f\" % log_loss(y_train_under, y_pred_under_train))\n",
        "print(\"Accuracy: %.2f\" % accuracy_score(y_train_under, y_pred_under_train))\n",
        "print('\\nOn testing set:')\n",
        "y_pred_under_test = model.predict(X_test)\n",
        "print(\"Cross entropy: %.2f\" % log_loss(y_test, y_pred_under_test))\n",
        "print(\"Accuracy: %.2f\" % accuracy_score(y_test, y_pred_under_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2wAUt_hjSzr"
      },
      "source": [
        "> What are the conclusions? (1-2 paragraphs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O dataset utilizado não estava originalmente balanceado, o que pode afetar o treinamento do modelo. Em busca de evitar esse desbalanceamento, foram empregadas duas técnicas: _oversampling_ e _underampling_. Para o conjunto de treinamento, o _oversampling_ teve um resultado ligeiramente melhor, porém, ainda com um valor baixo de acurácia, de apenas 63%. Novamente, assim como no primeiro modelo treinado, o resultado teve um desempenho abaixo do esperado, sendo pouco preciso nas suas predições."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pNHeah9jK7f"
      },
      "source": [
        "4. (0.5 points) Pick **your best model** and plot the confusion matrix in the **test set**. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "bak1v-ikjImM"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_confusion_matrix(y, y_pred):\n",
        "    data = {'y': y_test, 'y_pred': y_pred}\n",
        "    df = pd.DataFrame(data, columns=['y','y_pred'])\n",
        "    cm = pd.crosstab(df['y'], df['y_pred'], rownames=['Actual'], colnames=['Predicted'])\n",
        "    sn.heatmap(cm, annot=True)\n",
        "\n",
        "plot_confusion_matrix(y_test,y_pred_over_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38HbjwZSjRf1"
      },
      "source": [
        "> What are the conclusions? (1-2 paragraphs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A matriz de confusão foi plotada com base no modelo com _oversampling_. \n",
        "\n",
        "A partir da análise dessa figura, vê-se que o modelo tem uma maior capacidade de acertar os resultados negativos do que os positivos. Enquanto para resultados positivos o modelo acertou em 11 das vezes e errou 9, para resultados negativos o modelo acertou em 22 das vezes errando também apenas em 10. Em geral, trazendo a acurácia do modelo para 63% para o conjunto de teste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2zOMBnKmK4-"
      },
      "source": [
        "## Deadline\n",
        "\n",
        "Wednesday, April 19, 11:59 pm. \n",
        "\n",
        "Penalty policy for late submission: You are not encouraged to submit your assignment after due date. However, in case you do, your grade will be penalized as follows:\n",
        "- April 20, 11:59 pm : grade * 0.75\n",
        "- April 21, 11:59 pm : grade * 0.5\n",
        "- April 22, 11:59 pm : grade * 0.25\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK1R2Xfkmc6j"
      },
      "source": [
        "## Submission\n",
        "\n",
        "On Google Classroom, submit your Jupyter Notebook (in Portuguese or English).\n",
        "\n",
        "**This activity is NOT individual, it must be done in pairs (two-person group).**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
